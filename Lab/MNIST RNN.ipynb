{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN for bit parity problem\n",
    "Let's create a RNN that looks at a series of characters and reverses it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': 19, 'g': 6, 'c': 2, 'z': 25, 'l': 11, 'k': 10, 'h': 7, 'p': 15, 'a': 0, 'b': 1, 'i': 8, 'y': 24, 'w': 22, 'u': 20, 'e': 4, 'f': 5, 'o': 14, 'j': 9, 'n': 13, 'q': 16, 's': 18, 'm': 12, 'r': 17, 'v': 21, 'd': 3, 'x': 23}\n",
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n"
     ]
    }
   ],
   "source": [
    "char_id_dict = {char: idx for idx, char in enumerate(string.ascii_lowercase)}\n",
    "id_char_dict = {idx: char for idx, char in enumerate(string.ascii_lowercase)}\n",
    "\n",
    "def char2id(strArray):\n",
    "    return map(lambda c:char_id_dict[c], strArray)\n",
    "\n",
    "def id2char(intArray):\n",
    "    return map(lambda c:id_char_dict[c], intArray)\n",
    "\n",
    "print(char_id_dict)\n",
    "print(id_char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 3, 9, 10, 19]\n",
      "[19, 10, 9, 3, 21]\n",
      "['v', 'd', 'j', 'k', 't']\n",
      "[21, 3, 9, 10, 19]\n"
     ]
    }
   ],
   "source": [
    "def random_chars(length):\n",
    "    chars = ''.join(random.choice(string.ascii_lowercase) for _ in range(length))\n",
    "    chars = list(chars)\n",
    "    chars = list(char2id(chars))\n",
    "    return chars, chars[::-1]\n",
    "\n",
    "s, rev_s = random_chars(5)\n",
    "\n",
    "print(s)\n",
    "print(rev_s)\n",
    "\n",
    "one_hot = list(id2char(s))\n",
    "print(one_hot)\n",
    "print(list(char2id(one_hot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5) (3, 5)\n",
      "[[18 21 10 21 25]\n",
      " [ 1 20 17  8 16]\n",
      " [25  5 12  7  5]]\n",
      "[[25 21 10 21 18]\n",
      " [16  8 17 20  1]\n",
      " [ 5  7 12  5 25]]\n"
     ]
    }
   ],
   "source": [
    "def random_string_generator(batch_size=128, chars=5):\n",
    "    while True:\n",
    "        xy = [random_chars(chars) for _ in range(batch_size)]\n",
    "        x, y = zip(*((pair[0], pair[1]) for pair in xy))\n",
    "        yield np.array(x).reshape(batch_size, -1), np.array(y).reshape(batch_size, -1)\n",
    "\n",
    "randomStringGenerator = random_string_generator(batch_size=3)\n",
    "\n",
    "x, y = next(randomStringGenerator)\n",
    "print(x.shape, y.shape)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_x = tf.placeholder(tf.float32, shape=[None, 128, 5])\n",
    "tf_y = tf.placeholder(tf.int32, shape=[None, 128, 5])\n",
    "\n",
    "tf_init_state = tf.placeholder(tf.float32, [None, 5])\n",
    "\n",
    "\n",
    "iw = tf.Variable(tf.random_normal(shape=[5, 5]), dtype=tf.float32)\n",
    "ib = tf.Variable(tf.random_normal(shape=[1, 5]), dtype=tf.float32)\n",
    "\n",
    "sw = tf.Variable(tf.random_normal(shape=[5, 5]), dtype=tf.float32)\n",
    "sb = tf.Variable(tf.random_normal(shape=[1, 5]), dtype=tf.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  4.  8.]\n"
     ]
    }
   ],
   "source": [
    "def print_func(x):\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fn(previous_output, current_input):\n",
    "#     abc = tf.py_func(print_func, [previous_output], [tf.float32])\n",
    "    return previous_output * current_input\n",
    "\n",
    "elems = tf.Variable([1.0, 2.0, 2.0, 2.0])\n",
    "initializer = tf.constant(1.0)\n",
    "out = tf.scan(fn, elems, initializer=initializer)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(out))\n",
    "#     print(prev[1].eval())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN to estimate cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 2]\n",
      " [5 8 6]]\n",
      "[[  5.   5.   7.]\n",
      " [  5.  13.  19.]]\n"
     ]
    }
   ],
   "source": [
    "def input_target_generator(min_duration=5, max_duration=10, length=3, batch_size=1):\n",
    "    \"\"\" Generate toy input, target sequences.\n",
    "    \n",
    "    Each input sequence has values that are drawn from the standard normal\n",
    "    distribution, and each target sequence is the corresponding cumulative sum.\n",
    "    Sequence durations are chosen at random using a discrete uniform\n",
    "    distribution over `[min_duration, max_duration]`.\n",
    "    \n",
    "    Args:\n",
    "        min_duration: A positive integer. The minimum sequence duration.\n",
    "        max_duration: A positive integer. The maximum sequence duration.\n",
    "\n",
    "    Yields:\n",
    "        A tuple,\n",
    "        inputs: A 2-D float32 NumPy array with shape `[duration, 1]`.\n",
    "        targets: A 2-D float32 NumPy array with shape `[duration, 1]`.\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(batch_size):\n",
    "            duration = np.random.randint(min_duration, max_duration)\n",
    "            inputs = np.random.randn(duration).astype(np.float32)\n",
    "            inputs = np.random.randint(10, size=length)\n",
    "            targets = np.cumsum(inputs).astype(np.float32)\n",
    "            x.append(inputs)\n",
    "            y.append(targets)\n",
    "        yield np.stack(x), np.stack(y)\n",
    "        \n",
    "gen = input_target_generator(batch_size=2)\n",
    "\n",
    "x, y = next(gen)\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  3.  5.  7.]\n",
      "[ 2.  2.  4.  6.]\n",
      "[  2.   4.   6.  10.]\n"
     ]
    }
   ],
   "source": [
    "def fn(previous_output, current_input):\n",
    "    return previous_output + current_input\n",
    "\n",
    "elems = tf.Variable([1.0, 2.0, 2.0, 2.0])\n",
    "elems = tf.identity(elems)\n",
    "initializer = tf.constant(0.0)\n",
    "out = tf.scan(fn, elems, initializer=initializer)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(out))\n",
    "    \n",
    "    \n",
    "    \n",
    "def fn2(previous_output, current_input):\n",
    "    init, extra_init = previous_output\n",
    "    output = init + extra_init\n",
    "    return [extra_init, output]\n",
    "\n",
    "elems = tf.Variable([1.0, 2.0, 2.0, 2.0])\n",
    "elems = tf.identity(elems)\n",
    "initializer = tf.constant(0.0)\n",
    "extra_init = tf.constant(2.0)\n",
    "out = tf.scan(fn2, elems, initializer=[initializer, extra_init])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(out[0]))\n",
    "    print(sess.run(out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 1 and 2 for 'MatMul' (op: 'BatchMatMul') with input shapes: [1,256,1], [2,1,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 1 and 2 for 'MatMul' (op: 'BatchMatMul') with input shapes: [1,256,1], [2,1,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-528-2af5c2b3dd5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrnn_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrnn_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0my_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#     rnn_outputs.append(y_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-528-2af5c2b3dd5d>\u001b[0m in \u001b[0;36mrnn_cell\u001b[0;34m(h_prev, x_input, scopename)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# = (hidden,1) + (hidden, 1) + (hidden,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# = (hidden, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWxh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWhh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# (1,hidden) * (hidden, 1) + (input, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m       return gen_math_ops._batch_mat_mul(\n\u001b[0;32m-> 1735\u001b[0;31m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[0m\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_batch_mat_mul\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m    368\u001b[0m   \"\"\"\n\u001b[1;32m    369\u001b[0m   result = _op_def_lib.apply_op(\"BatchMatMul\", x=x, y=y, adj_x=adj_x,\n\u001b[0;32m--> 370\u001b[0;31m                                 adj_y=adj_y, name=name)\n\u001b[0m\u001b[1;32m    371\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    761\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    762\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2327\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2330\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2331\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1715\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/william/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 1 and 2 for 'MatMul' (op: 'BatchMatMul') with input shapes: [1,256,1], [2,1,1]."
     ]
    }
   ],
   "source": [
    "# http://blog.gaurav.im/2017/01/11/a-gentle-intro-to-recurrent-nns-in-tensorflow/\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 2\n",
    "input_size = 3\n",
    "# no_steps = 5\n",
    "hidden_size = 256\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, input_size], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, input_size], name=\"y\")\n",
    "init_state = tf.placeholder(tf.float32, shape=[batch_size, hidden_size, 1], name='state')\n",
    "\n",
    "def rnn_cell(h_prev, x_input, scopename):\n",
    "    with tf.variable_scope('rnn_cell' + scopename) as scope:\n",
    "        # seems the best way to bypass the reuse=True chicken egg scenario\n",
    "        try:\n",
    "            tf.get_variable('test', [1])\n",
    "        except ValueError:\n",
    "            scope.reuse_variables()\n",
    "        #init variables\n",
    "        Wxh = tf.get_variable('Wxh', [1, hidden_size, 1])\n",
    "        Whh = tf.get_variable('Whh', [1, hidden_size, hidden_size])\n",
    "        Why = tf.get_variable('Why', [1, 1, hidden_size])\n",
    "        bh = tf.get_variable('bh', [1, hidden_size, 1])\n",
    "        by = tf.get_variable('by', [1, 1, 1])\n",
    "        scope.reuse_variables()\n",
    "    \n",
    "    x_input = tf.expand_dims(x_input, 1)\n",
    "    x_input = tf.expand_dims(x_input, 1)\n",
    "    # (hidden,1) * (1,1)  + (hidden,hidden) * (hidden,1) + (hidden, 1)\n",
    "    # = (hidden,1) + (hidden, 1) + (hidden,1)\n",
    "    # = (hidden, 1)\n",
    "    next_state = tf.tanh(tf.matmul(Wxh, x_input) + tf.matmul(Whh, h_prev) + bh)\n",
    "    \n",
    "    # (1,hidden) * (hidden, 1) + (input, 1)\n",
    "    y_output = tf.matmul(Why, next_state) + by\n",
    "#     y_output = tf.zeros(shape=[input_size, 1])\n",
    "    return y_output, next_state\n",
    "\n",
    "rnn_inputs = tf.unstack(x, axis=1)\n",
    "rnn_targets = y#tf.unstack(y, axis=1)\n",
    "rnn_outputs = []\n",
    "\n",
    "state = init_state\n",
    "\n",
    "for rnn_input in rnn_inputs:\n",
    "    y_out, state = rnn_cell(state, rnn_input, 'encoder')\n",
    "    y_out = tf.squeeze(y_out)\n",
    "#     rnn_outputs.append(y_out)\n",
    "\n",
    "zero_input = tf.zeros([batch_size])\n",
    "\n",
    "# def decode(prev_output, current_input):\n",
    "#     input_var, state = prev_output\n",
    "#     decode_out, state = rnn_cell(state, input_var, 'decoder')\n",
    "#     decode_out = tf.squeeze(decode_out)\n",
    "#     return [decode_out, state]\n",
    "\n",
    "# rnn_outputs, state = tf.scan(decode, rnn_inputs, initializer=[zero_input, state])\n",
    "\n",
    "y_out, state = rnn_cell(state, zero_input, 'decoder')\n",
    "y_out = tf.squeeze(y_out)\n",
    "rnn_outputs = [y_out]\n",
    "\n",
    "y_out, state = rnn_cell(state, y_out, 'decoder')\n",
    "y_out = tf.squeeze(y_out)\n",
    "rnn_outputs.append(y_out)\n",
    "\n",
    "y_out, state = rnn_cell(state, y_out, 'decoder')\n",
    "y_out = tf.squeeze(y_out)\n",
    "rnn_outputs.append(y_out)\n",
    "\n",
    "rnn_outputs = tf.stack(rnn_outputs, axis=1)\n",
    "    \n",
    "gen = input_target_generator(length=input_size, batch_size=batch_size)\n",
    "\n",
    "loss = tf.squared_difference(rnn_targets, rnn_outputs, name=\"total_loss\")\n",
    "# loss = tf.reduce_sum(total_loss, name='mean_loss')  #mean of all losses\n",
    "\n",
    "# #learning_rate = 10e-8\n",
    "global_step = tf.Variable(0, trainable=False, dtype=tf.int32)\n",
    "# learning_rate = tf.train.exponential_decay(1e-2, global_step, 100, 0.9, staircase=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(5001):\n",
    "        sample_x, sample_y = next(gen)\n",
    "#         sample_x = np.array([[1],[2], [3], [4]])\n",
    "#         sample_y = np.array([[1], [3], [6], [10]])\n",
    "        epoch_state = np.zeros([batch_size, hidden_size, 1])\n",
    "        feed_dict = {x: sample_x, y: sample_y, init_state: epoch_state}\n",
    "        \n",
    "        o, l, opt = sess.run([rnn_outputs, loss, optimizer], feed_dict=feed_dict)\n",
    "#         o, t = sess.run([rnn_outputs, rnn_targets], feed_dict=feed_dict)\n",
    "#         print('run {0} --------'.format(epoch))\n",
    "#         print('target:', sample_y.squeeze())\n",
    "#         print('target:', np.squeeze(sample_y))\n",
    "#         print('input:', sample_x)\n",
    "#         print('output:', o)\n",
    "#         print('t:', t)\n",
    "#         print('loss:', l)\n",
    "    \n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Run ====={0}====\".format(epoch))\n",
    "            o, l, opt = sess.run([rnn_outputs, loss, optimizer], feed_dict=feed_dict)\n",
    "            print('target:', np.squeeze(sample_y))\n",
    "            print('output:', o)\n",
    "            print('loss:', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try chars instead, numbers didn't work very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randomStringGenerator = random_string_generator(batch_size=1)\n",
    "x, y = next(randomStringGenerator)\n",
    "print(x.shape, y.shape)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf_x = tf.constant(x)\n",
    "tf_y = tf.constant(y)\n",
    "\n",
    "tf_x_oh = tf.one_hot(tf_x, depth=26)\n",
    "tf_y_oh = tf.one_hot(tf_y, depth=26)\n",
    "\n",
    "test_x_oh = tf_x_oh.eval()\n",
    "print(list(id2char(x.squeeze().tolist())))\n",
    "print(test_x_oh.shape)\n",
    "print(np.argmax(test_x_oh, axis=2))\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "sequence_length=3\n",
    "input_size = 26 #no. of chars in onehot\n",
    "hidden_size = 128 #no. of hidden units\n",
    "\n",
    "tf_x = tf.placeholder(tf.int32, shape=[sequence_length], name=\"x\")\n",
    "tf_y = tf.placeholder(tf.int32, shape=[sequence_length], name=\"y\")\n",
    "tf_x_oh = tf.cast(tf.one_hot(tf_x, depth=26), tf.float32)\n",
    "tf_y_oh = tf.cast(tf.one_hot(tf_y, depth=26), tf.float32)\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, shape=[hidden_size, 1], name='state')\n",
    "\n",
    "# out = sess.run([tf_x_oh], feed_dict={tf_x: x})\n",
    "# print(np.array(out).shape)\n",
    "\n",
    "with tf.variable_scope('rnn_cell') as scope:\n",
    "    #init variables\n",
    "    Wxh = tf.get_variable('Wxh', [hidden_size, input_size])\n",
    "    Whh = tf.get_variable('Whh', [hidden_size, hidden_size])\n",
    "    Why = tf.get_variable('Why', [input_size, hidden_size])\n",
    "    bh = tf.get_variable('bh', [hidden_size, 1])\n",
    "    by = tf.get_variable('by', [input_size, 1])\n",
    "\n",
    "\n",
    "def rnn_cell(x_input, h_prev):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True) as scope:\n",
    "        Wxh = tf.get_variable('Wxh', [hidden_size, input_size])\n",
    "        Whh = tf.get_variable('Whh', [hidden_size, hidden_size])\n",
    "        Why = tf.get_variable('Why', [input_size, hidden_size])\n",
    "        bh = tf.get_variable('bh', [hidden_size, 1])\n",
    "        by = tf.get_variable('by', [input_size, 1])\n",
    "    \n",
    "    x_input = tf.expand_dims(x_input, 1)\n",
    "    # (hidden,input) * (input,input)  + (hidden,hidden) * (hidden,1) + (hidden, 1)\n",
    "    # = (hidden,input) + (hidden, 1) + (hidden,1)\n",
    "    # = (hidden, input)\n",
    "    next_state = tf.tanh(tf.matmul(Wxh, x_input) + tf.matmul(Whh, h_prev) + bh)\n",
    "    \n",
    "    # (input,hidden) * (hidden, 1) + (input, 1)\n",
    "    y_output = tf.matmul(Why, next_state) + by\n",
    "    return y_output, next_state\n",
    "\n",
    "\n",
    "rnn_inputs = tf.unstack(tf_x_oh)\n",
    "rnn_targets = tf.unstack(tf_y_oh)\n",
    "rnn_outputs = []\n",
    "\n",
    "# out = sess.run(rnn_inputs, feed_dict={tf_x: x[0]})\n",
    "# print(out)\n",
    "\n",
    "\n",
    "state = init_state\n",
    "for rnn_input in rnn_inputs:\n",
    "    y_out, state = rnn_cell(rnn_input, state)\n",
    "    y_out = tf.squeeze(y_out)\n",
    "    rnn_outputs.append(y_out)\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# epoch_state = np.zeros([hidden_size, 1])\n",
    "# out, target = sess.run([rnn_outputs, rnn_targets], feed_dict={tf_x: x[0], init_state: epoch_state, tf_y: y[0]})\n",
    "# print(out[0].shape)\n",
    "\n",
    "predictions = tf.argmax(rnn_outputs, axis=1)\n",
    "\n",
    "losses = [tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=target) \n",
    "              for logits, target in zip(rnn_outputs, rnn_targets)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "learning_rate = 1e-1\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(20000):\n",
    "        randomStringGenerator = random_string_generator(batch_size=256, chars=sequence_length)\n",
    "        x, y = next(randomStringGenerator)\n",
    "        print('run {0} --------'.format(epoch))\n",
    "        \n",
    "        for i in range(x.shape[0]):\n",
    "#             print('sample {0}'.format(i))\n",
    "            sample_x = x[i]\n",
    "            sample_y = y[i]\n",
    "            epoch_state = np.zeros([hidden_size, 1])\n",
    "            feed_dict = {tf_x: sample_x, tf_y: sample_y, init_state: epoch_state}\n",
    "            o, l, opt = sess.run([predictions, total_loss, optimizer], feed_dict=feed_dict)\n",
    "    #         print('target:', sample_y.squeeze())\n",
    "        print('target:', sample_y)\n",
    "        print('output:', o)\n",
    "        print('loss:', l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# That also doesn't seem to work\n",
    "# let's use Tensorflow's RNN cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0 --------\n",
      "target: [[20 10]\n",
      " [ 2 12]\n",
      " [17 15]\n",
      " [11 12]]\n",
      "output: [[20  3]\n",
      " [ 7  5]\n",
      " [23 17]\n",
      " [23 18]]\n",
      "loss: [[ 0.75843024  6.73534966]\n",
      " [ 5.32160854  6.38236284]\n",
      " [ 2.81987858  4.33962154]\n",
      " [ 4.14901686  1.68291402]]\n",
      "run 1000 --------\n",
      "target: [[13 16]\n",
      " [15 21]\n",
      " [10  4]\n",
      " [24 25]]\n",
      "output: [[ 1 16]\n",
      " [14 21]\n",
      " [14  4]\n",
      " [11 25]]\n",
      "loss: [[ 3.25473118  0.03441959]\n",
      " [ 2.63751173  0.0356067 ]\n",
      " [ 3.23337984  0.00560557]\n",
      " [ 2.79000473  0.00688774]]\n",
      "run 2000 --------\n",
      "target: [[ 3 19]\n",
      " [20 25]\n",
      " [22 14]\n",
      " [ 9  6]]\n",
      "output: [[ 2 19]\n",
      " [23 25]\n",
      " [23 14]\n",
      " [14  6]]\n",
      "loss: [[ 3.05199981  0.01422621]\n",
      " [ 4.00644588  0.00576702]\n",
      " [ 2.93528938  0.01180861]\n",
      " [ 3.82049513  0.00808502]]\n",
      "run 3000 --------\n",
      "target: [[16 22]\n",
      " [ 4  6]\n",
      " [ 0 20]\n",
      " [14  1]]\n",
      "output: [[16 22]\n",
      " [14  6]\n",
      " [20 20]\n",
      " [19  1]]\n",
      "loss: [[ 2.47166443  0.01254242]\n",
      " [ 4.19073772  0.01824373]\n",
      " [ 3.41091251  0.00890333]\n",
      " [ 4.03273249  0.01146867]]\n",
      "run 4000 --------\n",
      "target: [[17 16]\n",
      " [25 15]\n",
      " [ 5 20]\n",
      " [24  6]]\n",
      "output: [[10 16]\n",
      " [10 15]\n",
      " [15 20]\n",
      " [ 2  6]]\n",
      "loss: [[  3.59336877e+00   1.82509667e-03]\n",
      " [  2.78264952e+00   3.05198343e-03]\n",
      " [  3.09409761e+00   8.23057722e-03]\n",
      " [  3.28081703e+00   1.69514900e-03]]\n",
      "run 5000 --------\n",
      "target: [[ 7 15]\n",
      " [19 16]\n",
      " [ 6 13]\n",
      " [19 20]]\n",
      "output: [[20 15]\n",
      " [ 5 16]\n",
      " [24 13]\n",
      " [23 20]]\n",
      "loss: [[  3.35673714e+00   5.64765511e-03]\n",
      " [  3.75086141e+00   3.68000614e-03]\n",
      " [  4.20875216e+00   2.63201213e-03]\n",
      " [  3.89322257e+00   7.89449841e-04]]\n",
      "run 6000 --------\n",
      "target: [[21 17]\n",
      " [24 22]\n",
      " [ 1  1]\n",
      " [10  9]]\n",
      "output: [[25 17]\n",
      " [14 22]\n",
      " [23  1]\n",
      " [23  9]]\n",
      "loss: [[  3.15031576e+00   1.02586555e-03]\n",
      " [  3.32404876e+00   2.12384062e-03]\n",
      " [  4.01447964e+00   2.19497411e-03]\n",
      " [  3.28965545e+00   4.19154251e-03]]\n",
      "run 7000 --------\n",
      "target: [[18  7]\n",
      " [19 15]\n",
      " [ 7  7]\n",
      " [12 18]]\n",
      "output: [[13  7]\n",
      " [23 15]\n",
      " [19  7]\n",
      " [25 18]]\n",
      "loss: [[  2.80399919e+00   3.90930043e-04]\n",
      " [  3.35671854e+00   2.05257325e-04]\n",
      " [  3.32697439e+00   6.62822335e-04]\n",
      " [  4.22288990e+00   8.55556631e-04]]\n",
      "run 8000 --------\n",
      "target: [[10 13]\n",
      " [ 5 23]\n",
      " [ 5  9]\n",
      " [ 8 23]]\n",
      "output: [[19 13]\n",
      " [ 5 23]\n",
      " [15  9]\n",
      " [19 23]]\n",
      "loss: [[  3.91532111e+00   3.19549057e-04]\n",
      " [  2.11336327e+00   4.46696620e-04]\n",
      " [  3.64792633e+00   8.73660785e-04]\n",
      " [  3.44375753e+00   4.01773781e-04]]\n",
      "run 9000 --------\n",
      "target: [[20  6]\n",
      " [11 16]\n",
      " [ 5  5]\n",
      " [18 10]]\n",
      "output: [[ 0  6]\n",
      " [ 7 16]\n",
      " [10  5]\n",
      " [ 7 10]]\n",
      "loss: [[  3.36590028e+00   1.78082817e-04]\n",
      " [  3.32569838e+00   1.61038784e-04]\n",
      " [  2.68339944e+00   2.98217172e-04]\n",
      " [  3.62767935e+00   4.53845976e-04]]\n",
      "run 10000 --------\n",
      "target: [[21  8]\n",
      " [11 13]\n",
      " [ 3  4]\n",
      " [23 23]]\n",
      "output: [[17  8]\n",
      " [18 13]\n",
      " [21  4]\n",
      " [ 4 23]]\n",
      "loss: [[  3.75466347e+00   2.70568475e-04]\n",
      " [  3.16674900e+00   1.99178889e-04]\n",
      " [  3.15225983e+00   1.19559772e-04]\n",
      " [  2.99293852e+00   1.63422577e-04]]\n",
      "run 11000 --------\n",
      "target: [[ 8  0]\n",
      " [13 12]\n",
      " [ 0 16]\n",
      " [21  9]]\n",
      "output: [[ 3  0]\n",
      " [ 1 12]\n",
      " [10 16]\n",
      " [20  9]]\n",
      "loss: [[  3.62178135e+00   1.90716673e-04]\n",
      " [  3.58856606e+00   4.20799952e-05]\n",
      " [  3.87760305e+00   1.50907566e-04]\n",
      " [  3.20903540e+00   2.36840802e-04]]\n",
      "run 12000 --------\n",
      "target: [[ 4 14]\n",
      " [ 4 14]\n",
      " [16 11]\n",
      " [17 18]]\n",
      "output: [[13 14]\n",
      " [10 14]\n",
      " [ 5 11]\n",
      " [ 1 18]]\n",
      "loss: [[  2.90671420e+00   3.82654507e-05]\n",
      " [  2.55811882e+00   1.74983928e-04]\n",
      " [  2.98367500e+00   8.17742257e-05]\n",
      " [  3.07916141e+00   8.35622195e-05]]\n",
      "run 13000 --------\n",
      "target: [[21 21]\n",
      " [21 11]\n",
      " [ 8  3]\n",
      " [18 13]]\n",
      "output: [[25 21]\n",
      " [16 11]\n",
      " [ 2  3]\n",
      " [14 13]]\n",
      "loss: [[  3.46138787e+00   9.70316541e-05]\n",
      " [  3.02994871e+00   6.27021218e-05]\n",
      " [  3.50985193e+00   8.28470220e-05]\n",
      " [  3.65003371e+00   1.69620427e-04]]\n",
      "run 14000 --------\n",
      "target: [[18 22]\n",
      " [ 3  9]\n",
      " [19  3]\n",
      " [ 2 25]]\n",
      "output: [[ 3 22]\n",
      " [ 2  9]\n",
      " [17  3]\n",
      " [10 25]]\n",
      "loss: [[  4.11727619e+00   4.16031762e-05]\n",
      " [  3.83578610e+00   7.78406393e-05]\n",
      " [  4.15445518e+00   5.59075925e-05]\n",
      " [  3.17854381e+00   1.29929685e-04]]\n",
      "run 15000 --------\n",
      "target: [[10 18]\n",
      " [16  4]\n",
      " [18 22]\n",
      " [17  2]]\n",
      "output: [[17 18]\n",
      " [ 8  4]\n",
      " [22 22]\n",
      " [ 8  2]]\n",
      "loss: [[  2.87121367e+00   4.30336258e-05]\n",
      " [  3.12637234e+00   2.25303011e-05]\n",
      " [  2.90320706e+00   3.52853276e-05]\n",
      " [  3.15948987e+00   2.81329958e-05]]\n",
      "run 16000 --------\n",
      "target: [[ 0 18]\n",
      " [12 16]\n",
      " [19  4]\n",
      " [ 4 10]]\n",
      "output: [[ 6 18]\n",
      " [19 16]\n",
      " [19  4]\n",
      " [24 10]]\n",
      "loss: [[  3.15119314e+00   1.84772689e-05]\n",
      " [  3.37671280e+00   1.25168972e-05]\n",
      " [  2.47794747e+00   4.17223819e-05]\n",
      " [  3.83876085e+00   2.07422017e-05]]\n",
      "run 17000 --------\n",
      "target: [[22 11]\n",
      " [10 12]\n",
      " [ 0 22]\n",
      " [ 9  9]]\n",
      "output: [[23 11]\n",
      " [17 12]\n",
      " [24 22]\n",
      " [14  9]]\n",
      "loss: [[  3.14405632e+00   8.46382409e-06]\n",
      " [  4.52128029e+00   4.70865598e-05]\n",
      " [  4.13494873e+00   1.16824422e-05]\n",
      " [  2.96684194e+00   9.89432192e-06]]\n",
      "run 18000 --------\n",
      "target: [[12 11]\n",
      " [ 8 24]\n",
      " [ 9 17]\n",
      " [ 6 19]]\n",
      "output: [[17 11]\n",
      " [ 7 24]\n",
      " [ 3 17]\n",
      " [ 3 19]]\n",
      "loss: [[  4.06448555e+00   1.08479862e-05]\n",
      " [  3.71410728e+00   5.48361231e-06]\n",
      " [  3.17589760e+00   1.90734681e-06]\n",
      " [  2.78811431e+00   6.43728072e-06]]\n",
      "run 19000 --------\n",
      "target: [[25 16]\n",
      " [20  2]\n",
      " [23 22]\n",
      " [13  2]]\n",
      "output: [[ 3 16]\n",
      " [ 6  2]\n",
      " [ 8 22]\n",
      " [10  2]]\n",
      "loss: [[  3.46393347e+00   4.76836021e-06]\n",
      " [  2.86234260e+00   2.86101886e-06]\n",
      " [  3.28527355e+00   4.52994254e-06]\n",
      " [  3.38735294e+00   4.29152533e-06]]\n",
      "run 20000 --------\n",
      "target: [[ 0 23]\n",
      " [15 11]\n",
      " [ 2 17]\n",
      " [10 16]]\n",
      "output: [[20 23]\n",
      " [18 11]\n",
      " [ 8 17]\n",
      " [ 7 16]]\n",
      "loss: [[  3.47644997e+00   7.15253191e-06]\n",
      " [  3.22958207e+00   7.86778219e-06]\n",
      " [  3.10915160e+00   2.50339190e-06]\n",
      " [  2.74319077e+00   1.54971951e-06]]\n",
      "run 21000 --------\n",
      "target: [[21 15]\n",
      " [18 21]\n",
      " [ 3 13]\n",
      " [21 11]]\n",
      "output: [[24 15]\n",
      " [ 9 21]\n",
      " [25 13]\n",
      " [13 11]]\n",
      "loss: [[  3.56915021e+00   2.50339190e-06]\n",
      " [  3.53553963e+00   2.98022769e-06]\n",
      " [  3.27219152e+00   2.02655588e-06]\n",
      " [  3.18009067e+00   1.90734681e-06]]\n",
      "run 22000 --------\n",
      "target: [[10 22]\n",
      " [ 9 11]\n",
      " [17 18]\n",
      " [ 6 20]]\n",
      "output: [[18 22]\n",
      " [17 11]\n",
      " [20 18]\n",
      " [10 20]]\n",
      "loss: [[  3.38008308e+00   8.34464686e-07]\n",
      " [  3.15700054e+00   1.07288304e-06]\n",
      " [  3.98759294e+00   1.31130128e-06]\n",
      " [  2.74775362e+00   3.57627812e-07]]\n",
      "run 23000 --------\n",
      "target: [[24 23]\n",
      " [ 1  8]\n",
      " [ 6  8]\n",
      " [14  0]]\n",
      "output: [[ 0 23]\n",
      " [25  8]\n",
      " [24  8]\n",
      " [13  0]]\n",
      "loss: [[  3.87597752e+00   2.26497400e-06]\n",
      " [  3.25637293e+00   5.96046277e-07]\n",
      " [  3.62497902e+00   1.43051045e-06]\n",
      " [  2.66408849e+00   2.14576494e-06]]\n",
      "run 24000 --------\n",
      "target: [[ 9  5]\n",
      " [ 5 14]\n",
      " [13 17]\n",
      " [ 5  8]]\n",
      "output: [[ 3  5]\n",
      " [ 1 14]\n",
      " [ 2 17]\n",
      " [23  8]]\n",
      "loss: [[  3.43419552e+00   7.15255510e-07]\n",
      " [  3.61727524e+00   8.34464686e-07]\n",
      " [  2.81945634e+00   5.96046277e-07]\n",
      " [  3.56229258e+00   2.38418551e-07]]\n",
      "run 25000 --------\n",
      "target: [[18 19]\n",
      " [ 8  4]\n",
      " [11 17]\n",
      " [13  4]]\n",
      "output: [[23 19]\n",
      " [14  4]\n",
      " [21 17]\n",
      " [12  4]]\n",
      "loss: [[  3.44219780e+00   3.57627812e-07]\n",
      " [  3.30883479e+00   1.07288304e-06]\n",
      " [  3.71954203e+00   4.76837045e-07]\n",
      " [  3.46379089e+00   8.34464686e-07]]\n",
      "run 26000 --------\n",
      "target: [[16 11]\n",
      " [ 0  2]\n",
      " [25  6]\n",
      " [ 7 18]]\n",
      "output: [[17 11]\n",
      " [ 1  2]\n",
      " [13  6]\n",
      " [ 9 18]]\n",
      "loss: [[  3.66796565e+00   1.19209282e-07]\n",
      " [  3.15395641e+00   2.38418551e-07]\n",
      " [  3.73992109e+00   1.19209282e-07]\n",
      " [  2.91898727e+00   1.19209282e-07]]\n",
      "run 27000 --------\n",
      "target: [[ 5 19]\n",
      " [25 23]\n",
      " [10 24]\n",
      " [19  5]]\n",
      "output: [[23 19]\n",
      " [18 23]\n",
      " [17 24]\n",
      " [19  5]]\n",
      "loss: [[  3.61966038e+00   3.57627812e-07]\n",
      " [  3.49020863e+00   1.19209282e-07]\n",
      " [  3.03614259e+00   1.19209282e-07]\n",
      " [  2.43985605e+00   3.57627812e-07]]\n",
      "run 28000 --------\n",
      "target: [[10  3]\n",
      " [15 20]\n",
      " [21  2]\n",
      " [16 13]]\n",
      "output: [[13  3]\n",
      " [20 20]\n",
      " [ 2  2]\n",
      " [20 13]]\n",
      "loss: [[  3.72017479e+00   2.38418551e-07]\n",
      " [  3.15215397e+00   2.38418551e-07]\n",
      " [  3.23707914e+00   1.19209282e-07]\n",
      " [  3.53435659e+00   0.00000000e+00]]\n",
      "run 29000 --------\n",
      "target: [[21  3]\n",
      " [ 1 20]\n",
      " [12 13]\n",
      " [ 1  0]]\n",
      "output: [[ 4  3]\n",
      " [25 20]\n",
      " [23 13]\n",
      " [ 7  0]]\n",
      "loss: [[  3.12656355e+00   1.19209282e-07]\n",
      " [  4.27632141e+00   3.57627812e-07]\n",
      " [  3.48623323e+00   0.00000000e+00]\n",
      " [  3.34641600e+00   2.38418551e-07]]\n",
      "run 30000 --------\n",
      "target: [[ 3 14]\n",
      " [18  7]\n",
      " [16 24]\n",
      " [15 20]]\n",
      "output: [[ 8 14]\n",
      " [ 4  7]\n",
      " [ 9 24]\n",
      " [ 0 20]]\n",
      "loss: [[  3.25453281e+00   1.19209282e-07]\n",
      " [  3.05794740e+00   1.19209282e-07]\n",
      " [  3.66083407e+00   1.19209282e-07]\n",
      " [  3.61865568e+00   1.19209282e-07]]\n",
      "run 31000 --------\n",
      "target: [[25 16]\n",
      " [22 12]\n",
      " [17  8]\n",
      " [24  7]]\n",
      "output: [[25 16]\n",
      " [18 12]\n",
      " [21  8]\n",
      " [15  7]]\n",
      "loss: [[  2.23347092e+00   0.00000000e+00]\n",
      " [  2.85430408e+00   0.00000000e+00]\n",
      " [  3.04652214e+00   0.00000000e+00]\n",
      " [  3.38438702e+00   1.19209282e-07]]\n",
      "run 32000 --------\n",
      "target: [[20  6]\n",
      " [14 20]\n",
      " [20 18]\n",
      " [12 25]]\n",
      "output: [[ 1  6]\n",
      " [10 20]\n",
      " [ 3 18]\n",
      " [23 25]]\n",
      "loss: [[  3.57406092e+00   1.19209282e-07]\n",
      " [  2.58676052e+00   0.00000000e+00]\n",
      " [  3.63513994e+00   0.00000000e+00]\n",
      " [  3.74261522e+00   0.00000000e+00]]\n",
      "run 33000 --------\n",
      "target: [[ 3 14]\n",
      " [16 23]\n",
      " [20 23]\n",
      " [21  4]]\n",
      "output: [[24 14]\n",
      " [ 0 23]\n",
      " [16 23]\n",
      " [12  4]]\n",
      "loss: [[  3.88271570e+00   0.00000000e+00]\n",
      " [  3.27127457e+00   0.00000000e+00]\n",
      " [  3.41056776e+00   1.19209282e-07]\n",
      " [  3.69690609e+00   0.00000000e+00]]\n",
      "run 34000 --------\n",
      "target: [[ 6 15]\n",
      " [18 20]\n",
      " [22 12]\n",
      " [20 13]]\n",
      "output: [[ 0 15]\n",
      " [ 2 20]\n",
      " [11 12]\n",
      " [12 13]]\n",
      "loss: [[  4.17724943e+00   0.00000000e+00]\n",
      " [  3.32797503e+00   1.19209282e-07]\n",
      " [  3.53011060e+00   0.00000000e+00]\n",
      " [  3.60306573e+00   0.00000000e+00]]\n",
      "run 35000 --------\n",
      "target: [[22 15]\n",
      " [ 0  4]\n",
      " [12  2]\n",
      " [23 12]]\n",
      "output: [[20 15]\n",
      " [ 6  4]\n",
      " [23  2]\n",
      " [15 12]]\n",
      "loss: [[  3.19784188e+00   0.00000000e+00]\n",
      " [  3.12275243e+00   0.00000000e+00]\n",
      " [  3.31557608e+00   1.19209282e-07]\n",
      " [  3.43257499e+00   0.00000000e+00]]\n",
      "run 36000 --------\n",
      "target: [[19 16]\n",
      " [ 5 19]\n",
      " [23  1]\n",
      " [10 23]]\n",
      "output: [[15 16]\n",
      " [10 19]\n",
      " [18  1]\n",
      " [25 23]]\n",
      "loss: [[  3.65691900e+00   0.00000000e+00]\n",
      " [  3.70008826e+00   1.19209282e-07]\n",
      " [  3.01261282e+00   0.00000000e+00]\n",
      " [  3.66999102e+00   0.00000000e+00]]\n",
      "run 37000 --------\n",
      "target: [[18  5]\n",
      " [15  3]\n",
      " [ 2 13]\n",
      " [ 9  4]]\n",
      "output: [[25  5]\n",
      " [14  3]\n",
      " [20 13]\n",
      " [14  4]]\n",
      "loss: [[  3.44608068e+00   1.19209282e-07]\n",
      " [  3.32300282e+00   0.00000000e+00]\n",
      " [  3.52177000e+00   0.00000000e+00]\n",
      " [  3.10908389e+00   0.00000000e+00]]\n",
      "run 38000 --------\n",
      "target: [[22 16]\n",
      " [21 20]\n",
      " [19  1]\n",
      " [25 13]]\n",
      "output: [[20 16]\n",
      " [14 20]\n",
      " [ 0  1]\n",
      " [ 3 13]]\n",
      "loss: [[  2.93452787e+00   0.00000000e+00]\n",
      " [  3.23388767e+00   0.00000000e+00]\n",
      " [  3.74045801e+00   1.19209282e-07]\n",
      " [  3.42253828e+00   0.00000000e+00]]\n",
      "run 39000 --------\n",
      "target: [[ 8  5]\n",
      " [22  8]\n",
      " [21 21]\n",
      " [ 0 20]]\n",
      "output: [[ 9  5]\n",
      " [ 6  8]\n",
      " [ 3 21]\n",
      " [21 20]]\n",
      "loss: [[  3.14983058e+00   1.19209282e-07]\n",
      " [  2.61124992e+00   0.00000000e+00]\n",
      " [  3.16941047e+00   0.00000000e+00]\n",
      " [  3.57004309e+00   1.19209282e-07]]\n",
      "run 40000 --------\n",
      "target: [[25 24]\n",
      " [ 2  7]\n",
      " [ 1 13]\n",
      " [22 21]]\n",
      "output: [[15 24]\n",
      " [22  7]\n",
      " [22 13]\n",
      " [ 0 21]]\n",
      "loss: [[ 3.59067678  0.        ]\n",
      " [ 3.73899651  0.        ]\n",
      " [ 4.34909534  0.        ]\n",
      " [ 3.12540078  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size=4\n",
    "sequence_length=2\n",
    "input_size = 26 #no. of chars in onehot\n",
    "hidden_size = 128 #no. of hidden units\n",
    "\n",
    "tf_x = tf.placeholder(tf.int32, shape=[batch_size, sequence_length], name=\"x\")\n",
    "tf_y = tf.placeholder(tf.int32, shape=[batch_size, sequence_length], name=\"y\")\n",
    "tf_x_oh = tf.cast(tf.one_hot(tf_x, depth=input_size), tf.float32)\n",
    "tf_y_oh = tf.cast(tf.one_hot(tf_y, depth=input_size), tf.float32)\n",
    "\n",
    "rnn_outputs = []\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "init_state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "rnn_outputs, state = tf.nn.dynamic_rnn(cell, inputs=tf_x_oh, initial_state=init_state, dtype=tf.float32)\n",
    "\n",
    "Why = tf.Variable(tf.random_normal(shape=[batch_size, hidden_size, input_size], dtype=tf.float32))\n",
    "by = tf.Variable(tf.random_normal(shape=[batch_size, 1, input_size], dtype=tf.float32))\n",
    "\n",
    "logits = tf.matmul(rnn_outputs, Why) + by\n",
    "predictions = tf.argmax(logits, axis=2)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_y_oh)\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(40001):\n",
    "        randomStringGenerator = random_string_generator(batch_size=batch_size, chars=sequence_length)\n",
    "        x, y = next(randomStringGenerator)\n",
    "#         print('run {0} --------'.format(epoch))\n",
    "\n",
    "        feed_dict = {tf_x: x, tf_y: y}\n",
    "        o, l, opt = sess.run([predictions, loss, optimizer], feed_dict=feed_dict)\n",
    "        if(epoch % 1000 == 0):\n",
    "            print('run {0} --------'.format(epoch))\n",
    "#             print('input:', x)\n",
    "            print('target:', y)\n",
    "            print('output:', o)\n",
    "            print('loss:', l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# That can do batch but still doesn't yield best results\n",
    "# Let's try LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "simple_decoder_fn_inference() missing 6 required positional arguments: 'encoder_state', 'embeddings', 'start_of_sequence_id', 'end_of_sequence_id', 'maximum_length', and 'num_decoder_symbols'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-083df4c7677d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0minference_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_decoder_fn_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     outputs_inference, state_inference, context_state_inference = tf.contrib.seq2seq.dynamic_rnn_decoder(\n\u001b[1;32m     36\u001b[0m                                     \u001b[0mcell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: simple_decoder_fn_inference() missing 6 required positional arguments: 'encoder_state', 'embeddings', 'start_of_sequence_id', 'end_of_sequence_id', 'maximum_length', and 'num_decoder_symbols'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size=4\n",
    "sequence_length=5\n",
    "input_size = 26 #no. of chars in onehot\n",
    "hidden_size = 256 #no. of hidden units\n",
    "\n",
    "tf_x = tf.placeholder(tf.int32, shape=[batch_size, sequence_length], name=\"x\")\n",
    "tf_y = tf.placeholder(tf.int32, shape=[batch_size, sequence_length], name=\"y\")\n",
    "tf_x_oh = tf.cast(tf.one_hot(tf_x, depth=input_size), tf.float32) # [batch, sequence_length, 26]\n",
    "tf_y_oh = tf.cast(tf.one_hot(tf_y, depth=input_size), tf.float32) # [batch, sequence_length, 26]\n",
    "\n",
    "rnn_outputs = []\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "rnn_outputs, state = tf.nn.dynamic_rnn(cell, inputs=tf_x_oh, dtype=tf.float32)\n",
    "\n",
    "Why = tf.Variable(tf.random_normal(shape=[batch_size, hidden_size, input_size], dtype=tf.float32))\n",
    "by = tf.Variable(tf.random_normal(shape=[batch_size, 1, input_size], dtype=tf.float32))\n",
    "\n",
    "# test = None\n",
    "# def output_fn(time, cell_state, cell_input, cell_output, context_state):\n",
    "#     logits_inference = tf.matmul(cell_output, Why) + by\n",
    "#     predictions_inference = tf.argmax(logits_inference, axis=2)\n",
    "#     return True, cell_state, predictions_inference, cell_output, context_state\n",
    "\n",
    "with tf.variable_scope('decoder') as scope:\n",
    "    output_cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "    decoder_fn_train = tf.contrib.seq2seq.simple_decoder_fn_train(state)\n",
    "    outputs_train, state_train, context_state_train = tf.contrib.seq2seq.dynamic_rnn_decoder(cell=output_cell,\n",
    "                                    sequence_length=sequence_length, decoder_fn=decoder_fn_train, inputs=tf_y_oh)\n",
    "    \n",
    "    #Inference\n",
    "    inference_fn = tf.contrib.seq2seq.simple_decoder_fn_inference(state)\n",
    "    outputs_inference, state_inference, context_state_inference = tf.contrib.seq2seq.dynamic_rnn_decoder(\n",
    "                                    cell=output_cell,\n",
    "                                    sequence_length=sequence_length, decoder_fn=inference_fn)\n",
    "#     logits_inference = tf.matmul(outputs_inference, Why) + by\n",
    "#     predictions_inference = tf.argmax(logits_inference, axis=2)\n",
    "\n",
    "\n",
    "logits = tf.matmul(outputs_train, Why) + by\n",
    "predictions = tf.argmax(logits, axis=2)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_y_oh)\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        randomStringGenerator = random_string_generator(batch_size=batch_size, chars=sequence_length)\n",
    "        x, y = next(randomStringGenerator)\n",
    "#         print('run {0} --------'.format(epoch))\n",
    "\n",
    "        feed_dict = {tf_x: x, tf_y: y}\n",
    "        o, l, opt = sess.run([predictions, loss, optimizer], feed_dict=feed_dict)\n",
    "#         o, l, opt, s = sess.run([predictions, loss, optimizer, outputs_train], feed_dict=feed_dict)\n",
    "\n",
    "#         print(s.shape)\n",
    "        if(epoch % 1000 == 0):\n",
    "            print('run {0} --------'.format(epoch))\n",
    "#             print('input:', x)\n",
    "            print('target:', y)\n",
    "            print('output:', o)\n",
    "            print('loss:', l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)\n",
    "print(dir(mnist.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TrainGenerator(batch_size=128):\n",
    "    while True:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size*3)\n",
    "        batch_x = batch_x.reshape(-1, 28, 28)\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(batch_size):\n",
    "            img = np.concatenate((batch_x[i], batch_x[i+batch_size], batch_x[i+batch_size*2]), axis=1) #combine 3 images horizontally\n",
    "            label = [batch_y[i], batch_y[i+batch_size], batch_y[i+batch_size*2]]\n",
    "            x.append(img)\n",
    "            y.append(label)\n",
    "        \n",
    "        yield np.stack(x), np.stack(y)\n",
    "\n",
    "gen = TrainGenerator()\n",
    "x, y = next(gen)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "plt.imshow(x[0], cmap='gray')\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
