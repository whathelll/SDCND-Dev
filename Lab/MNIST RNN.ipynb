{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN for bit parity problem\n",
    "Let's create a RNN that looks at a series of characters and reverses it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': 19, 'g': 6, 'c': 2, 'z': 25, 'l': 11, 'k': 10, 'h': 7, 'p': 15, 'a': 0, 'b': 1, 'i': 8, 'y': 24, 'w': 22, 'u': 20, 'e': 4, 'f': 5, 'o': 14, 'j': 9, 'n': 13, 'q': 16, 's': 18, 'm': 12, 'r': 17, 'v': 21, 'd': 3, 'x': 23}\n",
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n"
     ]
    }
   ],
   "source": [
    "char_id_dict = {char: idx for idx, char in enumerate(string.ascii_lowercase)}\n",
    "id_char_dict = {idx: char for idx, char in enumerate(string.ascii_lowercase)}\n",
    "\n",
    "def char2id(strArray):\n",
    "    return map(lambda c:char_id_dict[c], strArray)\n",
    "\n",
    "def id2char(intArray):\n",
    "    return map(lambda c:id_char_dict[c], intArray)\n",
    "\n",
    "print(char_id_dict)\n",
    "print(id_char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 3, 9, 10, 19]\n",
      "[19, 10, 9, 3, 21]\n",
      "['v', 'd', 'j', 'k', 't']\n",
      "[21, 3, 9, 10, 19]\n"
     ]
    }
   ],
   "source": [
    "def random_chars(length):\n",
    "    chars = ''.join(random.choice(string.ascii_lowercase) for _ in range(length))\n",
    "    chars = list(chars)\n",
    "    chars = list(char2id(chars))\n",
    "    return chars, chars[::-1]\n",
    "\n",
    "s, rev_s = random_chars(5)\n",
    "\n",
    "print(s)\n",
    "print(rev_s)\n",
    "\n",
    "one_hot = list(id2char(s))\n",
    "print(one_hot)\n",
    "print(list(char2id(one_hot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5) (3, 5)\n",
      "[[18 21 10 21 25]\n",
      " [ 1 20 17  8 16]\n",
      " [25  5 12  7  5]]\n",
      "[[25 21 10 21 18]\n",
      " [16  8 17 20  1]\n",
      " [ 5  7 12  5 25]]\n"
     ]
    }
   ],
   "source": [
    "def random_string_generator(batch_size=128, chars=5):\n",
    "    while True:\n",
    "        xy = [random_chars(chars) for _ in range(batch_size)]\n",
    "        x, y = zip(*((pair[0], pair[1]) for pair in xy))\n",
    "        yield np.array(x).reshape(batch_size, -1), np.array(y).reshape(batch_size, -1)\n",
    "\n",
    "randomStringGenerator = random_string_generator(batch_size=3)\n",
    "\n",
    "x, y = next(randomStringGenerator)\n",
    "print(x.shape, y.shape)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_x = tf.placeholder(tf.float32, shape=[None, 128, 5])\n",
    "tf_y = tf.placeholder(tf.int32, shape=[None, 128, 5])\n",
    "\n",
    "tf_init_state = tf.placeholder(tf.float32, [None, 5])\n",
    "\n",
    "\n",
    "iw = tf.Variable(tf.random_normal(shape=[5, 5]), dtype=tf.float32)\n",
    "ib = tf.Variable(tf.random_normal(shape=[1, 5]), dtype=tf.float32)\n",
    "\n",
    "sw = tf.Variable(tf.random_normal(shape=[5, 5]), dtype=tf.float32)\n",
    "sb = tf.Variable(tf.random_normal(shape=[1, 5]), dtype=tf.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  4.  8.]\n"
     ]
    }
   ],
   "source": [
    "def print_func(x):\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fn(previous_output, current_input):\n",
    "#     abc = tf.py_func(print_func, [previous_output], [tf.float32])\n",
    "    return previous_output * current_input\n",
    "\n",
    "elems = tf.Variable([1.0, 2.0, 2.0, 2.0])\n",
    "initializer = tf.constant(1.0)\n",
    "out = tf.scan(fn, elems, initializer=initializer)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(out))\n",
    "#     print(prev[1].eval())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN to estimate cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_target_generator(min_duration=5, max_duration=10):\n",
    "    \"\"\" Generate toy input, target sequences.\n",
    "    \n",
    "    Each input sequence has values that are drawn from the standard normal\n",
    "    distribution, and each target sequence is the corresponding cumulative sum.\n",
    "    Sequence durations are chosen at random using a discrete uniform\n",
    "    distribution over `[min_duration, max_duration]`.\n",
    "    \n",
    "    Args:\n",
    "        min_duration: A positive integer. The minimum sequence duration.\n",
    "        max_duration: A positive integer. The maximum sequence duration.\n",
    "\n",
    "    Yields:\n",
    "        A tuple,\n",
    "        inputs: A 2-D float32 NumPy array with shape `[duration, 1]`.\n",
    "        targets: A 2-D float32 NumPy array with shape `[duration, 1]`.\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        duration = np.random.randint(min_duration, max_duration)\n",
    "        inputs = np.random.randn(duration).astype(np.float32)\n",
    "        inputs = np.random.randint(10, size=5)\n",
    "        targets = np.cumsum(inputs).astype(np.float32)\n",
    "        yield inputs.reshape(-1, 1), targets.reshape(-1, 1)\n",
    "        \n",
    "gen = input_target_generator()\n",
    "\n",
    "x, y = next(gen)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# http://blog.gaurav.im/2017/01/11/a-gentle-intro-to-recurrent-nns-in-tensorflow/\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_size = 1\n",
    "# no_steps = 5\n",
    "hidden_size = 256\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_size], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, input_size], name=\"y\")\n",
    "init_state = tf.placeholder(tf.float32, shape=[hidden_size, 1], name='state')\n",
    "\n",
    "def rnn_cell(x_input, h_prev):\n",
    "    with tf.variable_scope('rnn_cell') as scope:\n",
    "        # seems the best way to bypass the reuse=True chicken egg scenario\n",
    "        try:\n",
    "            tf.get_variable('test', [1])\n",
    "        except ValueError:\n",
    "            scope.reuse_variables()\n",
    "        #init variables\n",
    "        Wxh = tf.get_variable('Wxh', [hidden_size, input_size])\n",
    "        Whh = tf.get_variable('Whh', [hidden_size, hidden_size])\n",
    "        Why = tf.get_variable('Why', [input_size, hidden_size])\n",
    "        bh = tf.get_variable('bh', [hidden_size, 1])\n",
    "        by = tf.get_variable('by', [input_size, 1])\n",
    "        scope.reuse_variables()\n",
    "    \n",
    "    x_input = tf.expand_dims(x_input, 0)\n",
    "    # (hidden,input) * (input,input)  + (hidden,hidden) * (hidden,1) + (hidden, 1)\n",
    "    # = (hidden,input) + (hidden, 1) + (hidden,1)\n",
    "    # = (hidden, input)\n",
    "    next_state = tf.tanh(tf.matmul(Wxh, x_input) + tf.matmul(Whh, h_prev) + bh)\n",
    "    \n",
    "    # (input,hidden) * (hidden, 1) + (input, 1)\n",
    "    y_output = tf.matmul(Why, next_state) + by\n",
    "    return y_output, next_state\n",
    "\n",
    "rnn_inputs = tf.unstack(x, axis=1)\n",
    "rnn_targets = tf.unstack(y, axis=1)\n",
    "rnn_outputs = []\n",
    "\n",
    "state = init_state\n",
    "for rnn_input in rnn_inputs:\n",
    "    y_out, state = rnn_cell(rnn_input, state)\n",
    "    y_out = tf.squeeze(y_out)\n",
    "    rnn_outputs.append(y_out)\n",
    "\n",
    "gen = input_target_generator()\n",
    "\n",
    "# this is for testing a single run\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     sample_x, sample_y = next(gen)\n",
    "#     feed_dict = {x: sample_x, y: sample_y}\n",
    "#     i, o, t, l = sess.run([rnn_inputs, rnn_outputs, rnn_targets, loss], feed_dict=feed_dict)\n",
    "#     print('i', i)\n",
    "#     print('o', o)\n",
    "#     print('t', t)\n",
    "#     print('l', l)\n",
    "\n",
    "total_loss = tf.squared_difference(rnn_targets, rnn_outputs, name=\"total_loss\")\n",
    "# total_loss = tf.square(tf.subtract(rnn_targets, rnn_outputs))\n",
    "loss = tf.reduce_sum(total_loss, name='mean_loss')  #mean of all losses\n",
    "\n",
    "#learning_rate = 10e-8\n",
    "global_step = tf.Variable(0, trainable=False, dtype=tf.int32)\n",
    "learning_rate = tf.train.exponential_decay(1e-2, global_step, 100, 0.9, staircase=True)\n",
    "# learning_rate = 1e-2\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "# tf.scalar_summary('loss', loss)\n",
    "\n",
    "# Optimizer.\n",
    "# trainables = tf.trainable_variables()\n",
    "# grads = tf.gradients(loss, trainables)\n",
    "# grads, _ = tf.clip_by_global_norm(grads, clip_norm=1.0)\n",
    "# grad_var_pairs = zip(grads, trainables)\n",
    "\n",
    "# global_step = tf.Variable(0, trainable=False, dtype=tf.int32)\n",
    "# learning_rate = tf.train.exponential_decay(1e-2, global_step, 15000, 0.1, staircase=True)\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "# optimizer = optimizer.apply_gradients(grad_var_pairs,global_step=global_step)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(100000):\n",
    "        sample_x, sample_y = next(gen)\n",
    "        sample_x = np.array([[1],[2], [3], [4]])\n",
    "        sample_y = np.array([[1], [3], [6], [10]])\n",
    "        epoch_state = np.zeros([hidden_size, 1])\n",
    "        feed_dict = {x: sample_x, y: sample_y, init_state: epoch_state}\n",
    "        \n",
    "        o, l, opt = sess.run([rnn_outputs, loss, optimizer], feed_dict=feed_dict)\n",
    "#         print('run {0} --------'.format(epoch))\n",
    "#         print('target:', sample_y.squeeze())\n",
    "        print('target:', np.squeeze(sample_y))\n",
    "        print('output:', o)\n",
    "        print('loss:', l)\n",
    "\n",
    "        \n",
    "    sample_x = np.array([[1],[2], [2], [2]])\n",
    "    sample_y = np.array([[1], [3], [5], [7]])\n",
    "    epoch_state = np.zeros([hidden_size, 1])\n",
    "    feed_dict = {x: sample_x, y: sample_y, init_state: epoch_state}\n",
    "\n",
    "    o, l, opt = sess.run([rnn_outputs, loss, optimizer], feed_dict=feed_dict)\n",
    "    print('test')\n",
    "    print('output:', o)\n",
    "    print('loss:', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try chars instead, numbers didn't work very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randomStringGenerator = random_string_generator(batch_size=1)\n",
    "x, y = next(randomStringGenerator)\n",
    "print(x.shape, y.shape)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf_x = tf.constant(x)\n",
    "tf_y = tf.constant(y)\n",
    "\n",
    "tf_x_oh = tf.one_hot(tf_x, depth=26)\n",
    "tf_y_oh = tf.one_hot(tf_y, depth=26)\n",
    "\n",
    "test_x_oh = tf_x_oh.eval()\n",
    "print(list(id2char(x.squeeze().tolist())))\n",
    "print(test_x_oh.shape)\n",
    "print(np.argmax(test_x_oh, axis=2))\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "sequence_length=3\n",
    "input_size = 26 #no. of chars in onehot\n",
    "hidden_size = 128 #no. of hidden units\n",
    "\n",
    "tf_x = tf.placeholder(tf.int32, shape=[sequence_length], name=\"x\")\n",
    "tf_y = tf.placeholder(tf.int32, shape=[sequence_length], name=\"y\")\n",
    "tf_x_oh = tf.cast(tf.one_hot(tf_x, depth=26), tf.float32)\n",
    "tf_y_oh = tf.cast(tf.one_hot(tf_y, depth=26), tf.float32)\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, shape=[hidden_size, 1], name='state')\n",
    "\n",
    "# out = sess.run([tf_x_oh], feed_dict={tf_x: x})\n",
    "# print(np.array(out).shape)\n",
    "\n",
    "with tf.variable_scope('rnn_cell') as scope:\n",
    "    #init variables\n",
    "    Wxh = tf.get_variable('Wxh', [hidden_size, input_size])\n",
    "    Whh = tf.get_variable('Whh', [hidden_size, hidden_size])\n",
    "    Why = tf.get_variable('Why', [input_size, hidden_size])\n",
    "    bh = tf.get_variable('bh', [hidden_size, 1])\n",
    "    by = tf.get_variable('by', [input_size, 1])\n",
    "\n",
    "\n",
    "def rnn_cell(x_input, h_prev):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True) as scope:\n",
    "        Wxh = tf.get_variable('Wxh', [hidden_size, input_size])\n",
    "        Whh = tf.get_variable('Whh', [hidden_size, hidden_size])\n",
    "        Why = tf.get_variable('Why', [input_size, hidden_size])\n",
    "        bh = tf.get_variable('bh', [hidden_size, 1])\n",
    "        by = tf.get_variable('by', [input_size, 1])\n",
    "    \n",
    "    x_input = tf.expand_dims(x_input, 1)\n",
    "    # (hidden,input) * (input,input)  + (hidden,hidden) * (hidden,1) + (hidden, 1)\n",
    "    # = (hidden,input) + (hidden, 1) + (hidden,1)\n",
    "    # = (hidden, input)\n",
    "    next_state = tf.tanh(tf.matmul(Wxh, x_input) + tf.matmul(Whh, h_prev) + bh)\n",
    "    \n",
    "    # (input,hidden) * (hidden, 1) + (input, 1)\n",
    "    y_output = tf.matmul(Why, next_state) + by\n",
    "    return y_output, next_state\n",
    "\n",
    "\n",
    "rnn_inputs = tf.unstack(tf_x_oh)\n",
    "rnn_targets = tf.unstack(tf_y_oh)\n",
    "rnn_outputs = []\n",
    "\n",
    "# out = sess.run(rnn_inputs, feed_dict={tf_x: x[0]})\n",
    "# print(out)\n",
    "\n",
    "\n",
    "state = init_state\n",
    "for rnn_input in rnn_inputs:\n",
    "    y_out, state = rnn_cell(rnn_input, state)\n",
    "    y_out = tf.squeeze(y_out)\n",
    "    rnn_outputs.append(y_out)\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# epoch_state = np.zeros([hidden_size, 1])\n",
    "# out, target = sess.run([rnn_outputs, rnn_targets], feed_dict={tf_x: x[0], init_state: epoch_state, tf_y: y[0]})\n",
    "# print(out[0].shape)\n",
    "\n",
    "predictions = tf.argmax(rnn_outputs, axis=1)\n",
    "\n",
    "losses = [tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=target) \n",
    "              for logits, target in zip(rnn_outputs, rnn_targets)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "learning_rate = 1e-1\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(20000):\n",
    "        randomStringGenerator = random_string_generator(batch_size=256, chars=sequence_length)\n",
    "        x, y = next(randomStringGenerator)\n",
    "        print('run {0} --------'.format(epoch))\n",
    "        \n",
    "        for i in range(x.shape[0]):\n",
    "#             print('sample {0}'.format(i))\n",
    "            sample_x = x[i]\n",
    "            sample_y = y[i]\n",
    "            epoch_state = np.zeros([hidden_size, 1])\n",
    "            feed_dict = {tf_x: sample_x, tf_y: sample_y, init_state: epoch_state}\n",
    "            o, l, opt = sess.run([predictions, total_loss, optimizer], feed_dict=feed_dict)\n",
    "    #         print('target:', sample_y.squeeze())\n",
    "        print('target:', sample_y)\n",
    "        print('output:', o)\n",
    "        print('loss:', l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# That also doesn't seem to work\n",
    "# let's use Tensorflow's RNN cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0 --------\n",
      "target: [[20 10]\n",
      " [ 2 12]\n",
      " [17 15]\n",
      " [11 12]]\n",
      "output: [[20  3]\n",
      " [ 7  5]\n",
      " [23 17]\n",
      " [23 18]]\n",
      "loss: [[ 0.75843024  6.73534966]\n",
      " [ 5.32160854  6.38236284]\n",
      " [ 2.81987858  4.33962154]\n",
      " [ 4.14901686  1.68291402]]\n",
      "run 1000 --------\n",
      "target: [[13 16]\n",
      " [15 21]\n",
      " [10  4]\n",
      " [24 25]]\n",
      "output: [[ 1 16]\n",
      " [14 21]\n",
      " [14  4]\n",
      " [11 25]]\n",
      "loss: [[ 3.25473118  0.03441959]\n",
      " [ 2.63751173  0.0356067 ]\n",
      " [ 3.23337984  0.00560557]\n",
      " [ 2.79000473  0.00688774]]\n",
      "run 2000 --------\n",
      "target: [[ 3 19]\n",
      " [20 25]\n",
      " [22 14]\n",
      " [ 9  6]]\n",
      "output: [[ 2 19]\n",
      " [23 25]\n",
      " [23 14]\n",
      " [14  6]]\n",
      "loss: [[ 3.05199981  0.01422621]\n",
      " [ 4.00644588  0.00576702]\n",
      " [ 2.93528938  0.01180861]\n",
      " [ 3.82049513  0.00808502]]\n",
      "run 3000 --------\n",
      "target: [[16 22]\n",
      " [ 4  6]\n",
      " [ 0 20]\n",
      " [14  1]]\n",
      "output: [[16 22]\n",
      " [14  6]\n",
      " [20 20]\n",
      " [19  1]]\n",
      "loss: [[ 2.47166443  0.01254242]\n",
      " [ 4.19073772  0.01824373]\n",
      " [ 3.41091251  0.00890333]\n",
      " [ 4.03273249  0.01146867]]\n",
      "run 4000 --------\n",
      "target: [[17 16]\n",
      " [25 15]\n",
      " [ 5 20]\n",
      " [24  6]]\n",
      "output: [[10 16]\n",
      " [10 15]\n",
      " [15 20]\n",
      " [ 2  6]]\n",
      "loss: [[  3.59336877e+00   1.82509667e-03]\n",
      " [  2.78264952e+00   3.05198343e-03]\n",
      " [  3.09409761e+00   8.23057722e-03]\n",
      " [  3.28081703e+00   1.69514900e-03]]\n",
      "run 5000 --------\n",
      "target: [[ 7 15]\n",
      " [19 16]\n",
      " [ 6 13]\n",
      " [19 20]]\n",
      "output: [[20 15]\n",
      " [ 5 16]\n",
      " [24 13]\n",
      " [23 20]]\n",
      "loss: [[  3.35673714e+00   5.64765511e-03]\n",
      " [  3.75086141e+00   3.68000614e-03]\n",
      " [  4.20875216e+00   2.63201213e-03]\n",
      " [  3.89322257e+00   7.89449841e-04]]\n",
      "run 6000 --------\n",
      "target: [[21 17]\n",
      " [24 22]\n",
      " [ 1  1]\n",
      " [10  9]]\n",
      "output: [[25 17]\n",
      " [14 22]\n",
      " [23  1]\n",
      " [23  9]]\n",
      "loss: [[  3.15031576e+00   1.02586555e-03]\n",
      " [  3.32404876e+00   2.12384062e-03]\n",
      " [  4.01447964e+00   2.19497411e-03]\n",
      " [  3.28965545e+00   4.19154251e-03]]\n",
      "run 7000 --------\n",
      "target: [[18  7]\n",
      " [19 15]\n",
      " [ 7  7]\n",
      " [12 18]]\n",
      "output: [[13  7]\n",
      " [23 15]\n",
      " [19  7]\n",
      " [25 18]]\n",
      "loss: [[  2.80399919e+00   3.90930043e-04]\n",
      " [  3.35671854e+00   2.05257325e-04]\n",
      " [  3.32697439e+00   6.62822335e-04]\n",
      " [  4.22288990e+00   8.55556631e-04]]\n",
      "run 8000 --------\n",
      "target: [[10 13]\n",
      " [ 5 23]\n",
      " [ 5  9]\n",
      " [ 8 23]]\n",
      "output: [[19 13]\n",
      " [ 5 23]\n",
      " [15  9]\n",
      " [19 23]]\n",
      "loss: [[  3.91532111e+00   3.19549057e-04]\n",
      " [  2.11336327e+00   4.46696620e-04]\n",
      " [  3.64792633e+00   8.73660785e-04]\n",
      " [  3.44375753e+00   4.01773781e-04]]\n",
      "run 9000 --------\n",
      "target: [[20  6]\n",
      " [11 16]\n",
      " [ 5  5]\n",
      " [18 10]]\n",
      "output: [[ 0  6]\n",
      " [ 7 16]\n",
      " [10  5]\n",
      " [ 7 10]]\n",
      "loss: [[  3.36590028e+00   1.78082817e-04]\n",
      " [  3.32569838e+00   1.61038784e-04]\n",
      " [  2.68339944e+00   2.98217172e-04]\n",
      " [  3.62767935e+00   4.53845976e-04]]\n",
      "run 10000 --------\n",
      "target: [[21  8]\n",
      " [11 13]\n",
      " [ 3  4]\n",
      " [23 23]]\n",
      "output: [[17  8]\n",
      " [18 13]\n",
      " [21  4]\n",
      " [ 4 23]]\n",
      "loss: [[  3.75466347e+00   2.70568475e-04]\n",
      " [  3.16674900e+00   1.99178889e-04]\n",
      " [  3.15225983e+00   1.19559772e-04]\n",
      " [  2.99293852e+00   1.63422577e-04]]\n",
      "run 11000 --------\n",
      "target: [[ 8  0]\n",
      " [13 12]\n",
      " [ 0 16]\n",
      " [21  9]]\n",
      "output: [[ 3  0]\n",
      " [ 1 12]\n",
      " [10 16]\n",
      " [20  9]]\n",
      "loss: [[  3.62178135e+00   1.90716673e-04]\n",
      " [  3.58856606e+00   4.20799952e-05]\n",
      " [  3.87760305e+00   1.50907566e-04]\n",
      " [  3.20903540e+00   2.36840802e-04]]\n",
      "run 12000 --------\n",
      "target: [[ 4 14]\n",
      " [ 4 14]\n",
      " [16 11]\n",
      " [17 18]]\n",
      "output: [[13 14]\n",
      " [10 14]\n",
      " [ 5 11]\n",
      " [ 1 18]]\n",
      "loss: [[  2.90671420e+00   3.82654507e-05]\n",
      " [  2.55811882e+00   1.74983928e-04]\n",
      " [  2.98367500e+00   8.17742257e-05]\n",
      " [  3.07916141e+00   8.35622195e-05]]\n",
      "run 13000 --------\n",
      "target: [[21 21]\n",
      " [21 11]\n",
      " [ 8  3]\n",
      " [18 13]]\n",
      "output: [[25 21]\n",
      " [16 11]\n",
      " [ 2  3]\n",
      " [14 13]]\n",
      "loss: [[  3.46138787e+00   9.70316541e-05]\n",
      " [  3.02994871e+00   6.27021218e-05]\n",
      " [  3.50985193e+00   8.28470220e-05]\n",
      " [  3.65003371e+00   1.69620427e-04]]\n",
      "run 14000 --------\n",
      "target: [[18 22]\n",
      " [ 3  9]\n",
      " [19  3]\n",
      " [ 2 25]]\n",
      "output: [[ 3 22]\n",
      " [ 2  9]\n",
      " [17  3]\n",
      " [10 25]]\n",
      "loss: [[  4.11727619e+00   4.16031762e-05]\n",
      " [  3.83578610e+00   7.78406393e-05]\n",
      " [  4.15445518e+00   5.59075925e-05]\n",
      " [  3.17854381e+00   1.29929685e-04]]\n",
      "run 15000 --------\n",
      "target: [[10 18]\n",
      " [16  4]\n",
      " [18 22]\n",
      " [17  2]]\n",
      "output: [[17 18]\n",
      " [ 8  4]\n",
      " [22 22]\n",
      " [ 8  2]]\n",
      "loss: [[  2.87121367e+00   4.30336258e-05]\n",
      " [  3.12637234e+00   2.25303011e-05]\n",
      " [  2.90320706e+00   3.52853276e-05]\n",
      " [  3.15948987e+00   2.81329958e-05]]\n",
      "run 16000 --------\n",
      "target: [[ 0 18]\n",
      " [12 16]\n",
      " [19  4]\n",
      " [ 4 10]]\n",
      "output: [[ 6 18]\n",
      " [19 16]\n",
      " [19  4]\n",
      " [24 10]]\n",
      "loss: [[  3.15119314e+00   1.84772689e-05]\n",
      " [  3.37671280e+00   1.25168972e-05]\n",
      " [  2.47794747e+00   4.17223819e-05]\n",
      " [  3.83876085e+00   2.07422017e-05]]\n",
      "run 17000 --------\n",
      "target: [[22 11]\n",
      " [10 12]\n",
      " [ 0 22]\n",
      " [ 9  9]]\n",
      "output: [[23 11]\n",
      " [17 12]\n",
      " [24 22]\n",
      " [14  9]]\n",
      "loss: [[  3.14405632e+00   8.46382409e-06]\n",
      " [  4.52128029e+00   4.70865598e-05]\n",
      " [  4.13494873e+00   1.16824422e-05]\n",
      " [  2.96684194e+00   9.89432192e-06]]\n",
      "run 18000 --------\n",
      "target: [[12 11]\n",
      " [ 8 24]\n",
      " [ 9 17]\n",
      " [ 6 19]]\n",
      "output: [[17 11]\n",
      " [ 7 24]\n",
      " [ 3 17]\n",
      " [ 3 19]]\n",
      "loss: [[  4.06448555e+00   1.08479862e-05]\n",
      " [  3.71410728e+00   5.48361231e-06]\n",
      " [  3.17589760e+00   1.90734681e-06]\n",
      " [  2.78811431e+00   6.43728072e-06]]\n",
      "run 19000 --------\n",
      "target: [[25 16]\n",
      " [20  2]\n",
      " [23 22]\n",
      " [13  2]]\n",
      "output: [[ 3 16]\n",
      " [ 6  2]\n",
      " [ 8 22]\n",
      " [10  2]]\n",
      "loss: [[  3.46393347e+00   4.76836021e-06]\n",
      " [  2.86234260e+00   2.86101886e-06]\n",
      " [  3.28527355e+00   4.52994254e-06]\n",
      " [  3.38735294e+00   4.29152533e-06]]\n",
      "run 20000 --------\n",
      "target: [[ 0 23]\n",
      " [15 11]\n",
      " [ 2 17]\n",
      " [10 16]]\n",
      "output: [[20 23]\n",
      " [18 11]\n",
      " [ 8 17]\n",
      " [ 7 16]]\n",
      "loss: [[  3.47644997e+00   7.15253191e-06]\n",
      " [  3.22958207e+00   7.86778219e-06]\n",
      " [  3.10915160e+00   2.50339190e-06]\n",
      " [  2.74319077e+00   1.54971951e-06]]\n",
      "run 21000 --------\n",
      "target: [[21 15]\n",
      " [18 21]\n",
      " [ 3 13]\n",
      " [21 11]]\n",
      "output: [[24 15]\n",
      " [ 9 21]\n",
      " [25 13]\n",
      " [13 11]]\n",
      "loss: [[  3.56915021e+00   2.50339190e-06]\n",
      " [  3.53553963e+00   2.98022769e-06]\n",
      " [  3.27219152e+00   2.02655588e-06]\n",
      " [  3.18009067e+00   1.90734681e-06]]\n",
      "run 22000 --------\n",
      "target: [[10 22]\n",
      " [ 9 11]\n",
      " [17 18]\n",
      " [ 6 20]]\n",
      "output: [[18 22]\n",
      " [17 11]\n",
      " [20 18]\n",
      " [10 20]]\n",
      "loss: [[  3.38008308e+00   8.34464686e-07]\n",
      " [  3.15700054e+00   1.07288304e-06]\n",
      " [  3.98759294e+00   1.31130128e-06]\n",
      " [  2.74775362e+00   3.57627812e-07]]\n",
      "run 23000 --------\n",
      "target: [[24 23]\n",
      " [ 1  8]\n",
      " [ 6  8]\n",
      " [14  0]]\n",
      "output: [[ 0 23]\n",
      " [25  8]\n",
      " [24  8]\n",
      " [13  0]]\n",
      "loss: [[  3.87597752e+00   2.26497400e-06]\n",
      " [  3.25637293e+00   5.96046277e-07]\n",
      " [  3.62497902e+00   1.43051045e-06]\n",
      " [  2.66408849e+00   2.14576494e-06]]\n",
      "run 24000 --------\n",
      "target: [[ 9  5]\n",
      " [ 5 14]\n",
      " [13 17]\n",
      " [ 5  8]]\n",
      "output: [[ 3  5]\n",
      " [ 1 14]\n",
      " [ 2 17]\n",
      " [23  8]]\n",
      "loss: [[  3.43419552e+00   7.15255510e-07]\n",
      " [  3.61727524e+00   8.34464686e-07]\n",
      " [  2.81945634e+00   5.96046277e-07]\n",
      " [  3.56229258e+00   2.38418551e-07]]\n",
      "run 25000 --------\n",
      "target: [[18 19]\n",
      " [ 8  4]\n",
      " [11 17]\n",
      " [13  4]]\n",
      "output: [[23 19]\n",
      " [14  4]\n",
      " [21 17]\n",
      " [12  4]]\n",
      "loss: [[  3.44219780e+00   3.57627812e-07]\n",
      " [  3.30883479e+00   1.07288304e-06]\n",
      " [  3.71954203e+00   4.76837045e-07]\n",
      " [  3.46379089e+00   8.34464686e-07]]\n",
      "run 26000 --------\n",
      "target: [[16 11]\n",
      " [ 0  2]\n",
      " [25  6]\n",
      " [ 7 18]]\n",
      "output: [[17 11]\n",
      " [ 1  2]\n",
      " [13  6]\n",
      " [ 9 18]]\n",
      "loss: [[  3.66796565e+00   1.19209282e-07]\n",
      " [  3.15395641e+00   2.38418551e-07]\n",
      " [  3.73992109e+00   1.19209282e-07]\n",
      " [  2.91898727e+00   1.19209282e-07]]\n",
      "run 27000 --------\n",
      "target: [[ 5 19]\n",
      " [25 23]\n",
      " [10 24]\n",
      " [19  5]]\n",
      "output: [[23 19]\n",
      " [18 23]\n",
      " [17 24]\n",
      " [19  5]]\n",
      "loss: [[  3.61966038e+00   3.57627812e-07]\n",
      " [  3.49020863e+00   1.19209282e-07]\n",
      " [  3.03614259e+00   1.19209282e-07]\n",
      " [  2.43985605e+00   3.57627812e-07]]\n",
      "run 28000 --------\n",
      "target: [[10  3]\n",
      " [15 20]\n",
      " [21  2]\n",
      " [16 13]]\n",
      "output: [[13  3]\n",
      " [20 20]\n",
      " [ 2  2]\n",
      " [20 13]]\n",
      "loss: [[  3.72017479e+00   2.38418551e-07]\n",
      " [  3.15215397e+00   2.38418551e-07]\n",
      " [  3.23707914e+00   1.19209282e-07]\n",
      " [  3.53435659e+00   0.00000000e+00]]\n",
      "run 29000 --------\n",
      "target: [[21  3]\n",
      " [ 1 20]\n",
      " [12 13]\n",
      " [ 1  0]]\n",
      "output: [[ 4  3]\n",
      " [25 20]\n",
      " [23 13]\n",
      " [ 7  0]]\n",
      "loss: [[  3.12656355e+00   1.19209282e-07]\n",
      " [  4.27632141e+00   3.57627812e-07]\n",
      " [  3.48623323e+00   0.00000000e+00]\n",
      " [  3.34641600e+00   2.38418551e-07]]\n",
      "run 30000 --------\n",
      "target: [[ 3 14]\n",
      " [18  7]\n",
      " [16 24]\n",
      " [15 20]]\n",
      "output: [[ 8 14]\n",
      " [ 4  7]\n",
      " [ 9 24]\n",
      " [ 0 20]]\n",
      "loss: [[  3.25453281e+00   1.19209282e-07]\n",
      " [  3.05794740e+00   1.19209282e-07]\n",
      " [  3.66083407e+00   1.19209282e-07]\n",
      " [  3.61865568e+00   1.19209282e-07]]\n",
      "run 31000 --------\n",
      "target: [[25 16]\n",
      " [22 12]\n",
      " [17  8]\n",
      " [24  7]]\n",
      "output: [[25 16]\n",
      " [18 12]\n",
      " [21  8]\n",
      " [15  7]]\n",
      "loss: [[  2.23347092e+00   0.00000000e+00]\n",
      " [  2.85430408e+00   0.00000000e+00]\n",
      " [  3.04652214e+00   0.00000000e+00]\n",
      " [  3.38438702e+00   1.19209282e-07]]\n",
      "run 32000 --------\n",
      "target: [[20  6]\n",
      " [14 20]\n",
      " [20 18]\n",
      " [12 25]]\n",
      "output: [[ 1  6]\n",
      " [10 20]\n",
      " [ 3 18]\n",
      " [23 25]]\n",
      "loss: [[  3.57406092e+00   1.19209282e-07]\n",
      " [  2.58676052e+00   0.00000000e+00]\n",
      " [  3.63513994e+00   0.00000000e+00]\n",
      " [  3.74261522e+00   0.00000000e+00]]\n",
      "run 33000 --------\n",
      "target: [[ 3 14]\n",
      " [16 23]\n",
      " [20 23]\n",
      " [21  4]]\n",
      "output: [[24 14]\n",
      " [ 0 23]\n",
      " [16 23]\n",
      " [12  4]]\n",
      "loss: [[  3.88271570e+00   0.00000000e+00]\n",
      " [  3.27127457e+00   0.00000000e+00]\n",
      " [  3.41056776e+00   1.19209282e-07]\n",
      " [  3.69690609e+00   0.00000000e+00]]\n",
      "run 34000 --------\n",
      "target: [[ 6 15]\n",
      " [18 20]\n",
      " [22 12]\n",
      " [20 13]]\n",
      "output: [[ 0 15]\n",
      " [ 2 20]\n",
      " [11 12]\n",
      " [12 13]]\n",
      "loss: [[  4.17724943e+00   0.00000000e+00]\n",
      " [  3.32797503e+00   1.19209282e-07]\n",
      " [  3.53011060e+00   0.00000000e+00]\n",
      " [  3.60306573e+00   0.00000000e+00]]\n",
      "run 35000 --------\n",
      "target: [[22 15]\n",
      " [ 0  4]\n",
      " [12  2]\n",
      " [23 12]]\n",
      "output: [[20 15]\n",
      " [ 6  4]\n",
      " [23  2]\n",
      " [15 12]]\n",
      "loss: [[  3.19784188e+00   0.00000000e+00]\n",
      " [  3.12275243e+00   0.00000000e+00]\n",
      " [  3.31557608e+00   1.19209282e-07]\n",
      " [  3.43257499e+00   0.00000000e+00]]\n",
      "run 36000 --------\n",
      "target: [[19 16]\n",
      " [ 5 19]\n",
      " [23  1]\n",
      " [10 23]]\n",
      "output: [[15 16]\n",
      " [10 19]\n",
      " [18  1]\n",
      " [25 23]]\n",
      "loss: [[  3.65691900e+00   0.00000000e+00]\n",
      " [  3.70008826e+00   1.19209282e-07]\n",
      " [  3.01261282e+00   0.00000000e+00]\n",
      " [  3.66999102e+00   0.00000000e+00]]\n",
      "run 37000 --------\n",
      "target: [[18  5]\n",
      " [15  3]\n",
      " [ 2 13]\n",
      " [ 9  4]]\n",
      "output: [[25  5]\n",
      " [14  3]\n",
      " [20 13]\n",
      " [14  4]]\n",
      "loss: [[  3.44608068e+00   1.19209282e-07]\n",
      " [  3.32300282e+00   0.00000000e+00]\n",
      " [  3.52177000e+00   0.00000000e+00]\n",
      " [  3.10908389e+00   0.00000000e+00]]\n",
      "run 38000 --------\n",
      "target: [[22 16]\n",
      " [21 20]\n",
      " [19  1]\n",
      " [25 13]]\n",
      "output: [[20 16]\n",
      " [14 20]\n",
      " [ 0  1]\n",
      " [ 3 13]]\n",
      "loss: [[  2.93452787e+00   0.00000000e+00]\n",
      " [  3.23388767e+00   0.00000000e+00]\n",
      " [  3.74045801e+00   1.19209282e-07]\n",
      " [  3.42253828e+00   0.00000000e+00]]\n",
      "run 39000 --------\n",
      "target: [[ 8  5]\n",
      " [22  8]\n",
      " [21 21]\n",
      " [ 0 20]]\n",
      "output: [[ 9  5]\n",
      " [ 6  8]\n",
      " [ 3 21]\n",
      " [21 20]]\n",
      "loss: [[  3.14983058e+00   1.19209282e-07]\n",
      " [  2.61124992e+00   0.00000000e+00]\n",
      " [  3.16941047e+00   0.00000000e+00]\n",
      " [  3.57004309e+00   1.19209282e-07]]\n",
      "run 40000 --------\n",
      "target: [[25 24]\n",
      " [ 2  7]\n",
      " [ 1 13]\n",
      " [22 21]]\n",
      "output: [[15 24]\n",
      " [22  7]\n",
      " [22 13]\n",
      " [ 0 21]]\n",
      "loss: [[ 3.59067678  0.        ]\n",
      " [ 3.73899651  0.        ]\n",
      " [ 4.34909534  0.        ]\n",
      " [ 3.12540078  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size=4\n",
    "sequence_length=2\n",
    "input_size = 26 #no. of chars in onehot\n",
    "hidden_size = 128 #no. of hidden units\n",
    "\n",
    "tf_x = tf.placeholder(tf.int32, shape=[batch_size, sequence_length], name=\"x\")\n",
    "tf_y = tf.placeholder(tf.int32, shape=[batch_size, sequence_length], name=\"y\")\n",
    "tf_x_oh = tf.cast(tf.one_hot(tf_x, depth=input_size), tf.float32)\n",
    "tf_y_oh = tf.cast(tf.one_hot(tf_y, depth=input_size), tf.float32)\n",
    "\n",
    "rnn_outputs = []\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "init_state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "rnn_outputs, state = tf.nn.dynamic_rnn(cell, inputs=tf_x_oh, initial_state=init_state, dtype=tf.float32)\n",
    "\n",
    "Why = tf.Variable(tf.random_normal(shape=[batch_size, hidden_size, input_size], dtype=tf.float32))\n",
    "by = tf.Variable(tf.random_normal(shape=[batch_size, 1, input_size], dtype=tf.float32))\n",
    "\n",
    "logits = tf.matmul(rnn_outputs, Why) + by\n",
    "predictions = tf.argmax(logits, axis=2)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_y_oh)\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(40001):\n",
    "        randomStringGenerator = random_string_generator(batch_size=batch_size, chars=sequence_length)\n",
    "        x, y = next(randomStringGenerator)\n",
    "#         print('run {0} --------'.format(epoch))\n",
    "\n",
    "        feed_dict = {tf_x: x, tf_y: y}\n",
    "        o, l, opt = sess.run([predictions, loss, optimizer], feed_dict=feed_dict)\n",
    "        if(epoch % 1000 == 0):\n",
    "            print('run {0} --------'.format(epoch))\n",
    "#             print('input:', x)\n",
    "            print('target:', y)\n",
    "            print('output:', o)\n",
    "            print('loss:', l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# That can do batch but still doesn't yield best results\n",
    "# Let's try LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0 --------\n",
      "target: [[18 17 12  9  4]\n",
      " [14  4 11 10  8]\n",
      " [ 8 16 16 18 22]\n",
      " [18  3  5  7  5]]\n",
      "output: [[25 25 25 25 25]\n",
      " [ 3  3  3  3  3]\n",
      " [16 16 16 16 16]\n",
      " [22 22 22 22 22]]\n",
      "loss: [[ 3.99598145  2.03370667  2.95125008  5.04148579  2.95154524]\n",
      " [ 4.71193981  1.89380407  4.68060637  3.88002777  4.80885935]\n",
      " [ 3.33564949  1.78692639  1.60105419  5.07365799  3.19068766]\n",
      " [ 2.77111387  4.94262218  3.98174572  4.44483852  3.89887571]]\n",
      "run 1000 --------\n",
      "target: [[ 1  6  4 17 17]\n",
      " [ 4 20  3  7  9]\n",
      " [19  0 11  9 23]\n",
      " [13 18 22  4  8]]\n",
      "output: [[17 17  4 17 17]\n",
      " [ 4  9  3  7  9]\n",
      " [19  0 11 11 11]\n",
      " [13 18 13  4  8]]\n",
      "loss: [[ 1.53822148  1.28141224  1.13064313  0.42904699  0.14492948]\n",
      " [ 1.76259065  2.72250891  1.27946281  0.965078    1.36483109]\n",
      " [ 1.90846515  1.69712126  0.41127491  2.39304447  1.65079737]\n",
      " [ 1.47106874  1.28372741  1.98476005  0.9570452   1.31488824]]\n",
      "run 2000 --------\n",
      "target: [[14  9  6 24  6]\n",
      " [13 11  5  1  5]\n",
      " [19 23  3  7  8]\n",
      " [25 22 18 12 23]]\n",
      "output: [[14  9  6 24  6]\n",
      " [13 11  5  1  5]\n",
      " [19 23  3  7  8]\n",
      " [25 22 18 12 23]]\n",
      "loss: [[ 0.28930432  0.1779002   0.03984312  0.10130091  0.12675248]\n",
      " [ 0.36771503  0.0608131   0.03219353  0.12198509  0.01305332]\n",
      " [ 0.51889879  0.27326733  0.14166787  0.14570089  0.12569712]\n",
      " [ 0.1359725   0.2954613   0.18223596  0.04758879  0.44884694]]\n",
      "run 3000 --------\n",
      "target: [[ 1  4 12  7 10]\n",
      " [11 25 23 17 14]\n",
      " [25 22 20 10  7]\n",
      " [18 21 20  2 19]]\n",
      "output: [[ 1  4 12  7 10]\n",
      " [11 25 23 17 14]\n",
      " [25 22 20 10  7]\n",
      " [18 21 20  2 19]]\n",
      "loss: [[ 0.11479113  0.03170513  0.11709053  0.0303678   0.09378348]\n",
      " [ 0.16209158  0.02924149  0.09797996  0.02463281  0.09995031]\n",
      " [ 0.0620233   0.03083073  0.09248909  0.03966567  0.39933041]\n",
      " [ 0.16153601  0.07782145  0.02070632  0.02775628  0.08346603]]\n",
      "run 4000 --------\n",
      "target: [[17 10  6 16  4]\n",
      " [ 8  9  9 10  1]\n",
      " [22 25 24 22 18]\n",
      " [24  0 20  8  7]]\n",
      "output: [[17 10  6 16  4]\n",
      " [ 8  9  9 10  1]\n",
      " [22 25 24 22 18]\n",
      " [24  0 20  8  7]]\n",
      "loss: [[ 0.01848319  0.03315912  0.00715728  0.03145276  0.04329323]\n",
      " [ 0.03116091  0.00443879  0.00212194  0.02001132  0.08283922]\n",
      " [ 0.00807391  0.05124293  0.02192439  0.01314698  0.02715063]\n",
      " [ 0.03145576  0.04141985  0.01292953  0.05795627  0.06717005]]\n",
      "run 5000 --------\n",
      "target: [[14 18 19 16 15]\n",
      " [ 0 23 14 13 15]\n",
      " [ 7  0 22  0 13]\n",
      " [20  8  4 20  1]]\n",
      "output: [[14 18 19 16 15]\n",
      " [ 0 23 14 13 15]\n",
      " [ 7  0 22  0 13]\n",
      " [20  8  4 20  1]]\n",
      "loss: [[ 0.03206966  0.00176441  0.01589544  0.00779882  0.02200544]\n",
      " [ 0.01472721  0.00166385  0.03134925  0.02894101  0.01684582]\n",
      " [ 0.25286707  0.00079672  0.02501748  0.00459911  0.0030836 ]\n",
      " [ 0.00334002  0.03004811  0.00783785  0.0043468   0.02565383]]\n",
      "run 6000 --------\n",
      "target: [[11 10 23  8  4]\n",
      " [ 5  7 24 19 18]\n",
      " [19 11  2 14 19]\n",
      " [12  1 20 18 22]]\n",
      "output: [[11 10 23  8  4]\n",
      " [ 5  7 24 19 18]\n",
      " [19 11  2 14 19]\n",
      " [12  1 20 18 22]]\n",
      "loss: [[ 0.0062192   0.00535743  0.01219825  0.00516521  0.00413337]\n",
      " [ 0.00411034  0.00381896  0.01282079  0.00440389  0.00498066]\n",
      " [ 0.00199012  0.01288929  0.01791217  0.0072606   0.00581525]\n",
      " [ 0.02210502  0.00571664  0.00936366  0.00391313  0.0122496 ]]\n",
      "run 7000 --------\n",
      "target: [[12  9 19 13  9]\n",
      " [20 17 18 17  3]\n",
      " [12 18  9 25 10]\n",
      " [ 6 16  6  6  3]]\n",
      "output: [[12  9 19 13  9]\n",
      " [20 17 18 17  3]\n",
      " [12 18  9 25 10]\n",
      " [ 6 16  6  6  3]]\n",
      "loss: [[ 0.01224383  0.00079529  0.00859207  0.00443855  0.0022209 ]\n",
      " [ 0.00464195  0.00102944  0.00224683  0.00068796  0.01487216]\n",
      " [ 0.00297544  0.0166905   0.00280238  0.00222114  0.00734545]\n",
      " [ 0.00042763  0.0432938   0.00028821  0.00010097  0.08562911]]\n",
      "run 8000 --------\n",
      "target: [[21  5 13 19 14]\n",
      " [22 24 23 13 10]\n",
      " [ 4 16 23 24 24]\n",
      " [19 19 12  9 15]]\n",
      "output: [[21  5 13 19 14]\n",
      " [22 24 23 13 10]\n",
      " [ 4 16 23 24 24]\n",
      " [19 19 12  9 15]]\n",
      "loss: [[ 0.00112685  0.00167932  0.00457811  0.00223316  0.00850377]\n",
      " [ 0.00247886  0.00149341  0.00193789  0.00298578  0.00305198]\n",
      " [ 0.00522913  0.00185889  0.00455722  0.00026616  0.00031871]\n",
      " [ 0.00053582  0.0004486   0.00224101  0.0017268   0.00339373]]\n",
      "run 9000 --------\n",
      "target: [[ 1  6  1 18 25]\n",
      " [ 4  0 19 22 23]\n",
      " [20  2 15 14 20]\n",
      " [10 17 18 22 12]]\n",
      "output: [[ 1  6  1 18 25]\n",
      " [ 4  0 19 22 23]\n",
      " [20  2 15 14 20]\n",
      " [10 17 18 22 12]]\n",
      "loss: [[  6.97350042e-05   1.44607630e-02   5.32723614e-04   1.77618978e-03\n",
      "    6.88673288e-04]\n",
      " [  1.63623865e-03   2.14596628e-03   4.42883640e-04   2.23339349e-03\n",
      "    1.54209381e-03]\n",
      " [  1.96080058e-04   1.93884643e-03   2.59574829e-03   8.46266164e-04\n",
      "    4.18869359e-03]\n",
      " [  1.93444430e-03   1.23591314e-03   2.76611792e-03   4.06617625e-03\n",
      "    4.82501928e-03]]\n",
      "run 10000 --------\n",
      "target: [[ 3 21 14  2  7]\n",
      " [ 7 19 13 10 17]\n",
      " [10 19 16  9  8]\n",
      " [23  3  5 25  9]]\n",
      "output: [[ 3 21 14  2  7]\n",
      " [ 7 19 13 10 17]\n",
      " [10 19 16  9  8]\n",
      " [23  3  5 25  9]]\n",
      "loss: [[ 0.00030465  0.00098466  0.00197014  0.00112673  0.00137806]\n",
      " [ 0.0010055   0.00114864  0.0005662   0.00086151  0.00084103]\n",
      " [ 0.00071917  0.00261453  0.00105337  0.00150627  0.0010342 ]\n",
      " [ 0.00153674  0.00052045  0.00075145  0.00064162  0.00258326]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size=4\n",
    "sequence_length=5\n",
    "input_size = 26 #no. of chars in onehot\n",
    "hidden_size = 256 #no. of hidden units\n",
    "\n",
    "tf_x = tf.placeholder(tf.int32, shape=[batch_size, sequence_length], name=\"x\")\n",
    "tf_y = tf.placeholder(tf.int32, shape=[batch_size, sequence_length], name=\"y\")\n",
    "tf_x_oh = tf.cast(tf.one_hot(tf_x, depth=input_size), tf.float32) # [batch, sequence_length, 26]\n",
    "tf_y_oh = tf.cast(tf.one_hot(tf_y, depth=input_size), tf.float32) # [batch, sequence_length, 26]\n",
    "\n",
    "rnn_outputs = []\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "rnn_outputs, state = tf.nn.dynamic_rnn(cell, inputs=tf_x_oh, dtype=tf.float32)\n",
    "\n",
    "Why = tf.Variable(tf.random_normal(shape=[batch_size, hidden_size, input_size], dtype=tf.float32))\n",
    "by = tf.Variable(tf.random_normal(shape=[batch_size, 1, input_size], dtype=tf.float32))\n",
    "\n",
    "with tf.variable_scope('decoder') as scope:\n",
    "    output_cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "    decoder_fn_train = tf.contrib.seq2seq.simple_decoder_fn_train(state)\n",
    "    outputs_train, state_train, context_state_train = tf.contrib.seq2seq.dynamic_rnn_decoder(cell=output_cell,\n",
    "                                    sequence_length=sequence_length, decoder_fn=decoder_fn_train, inputs=tf_y_oh)\n",
    "\n",
    "logits = tf.matmul(outputs_train, Why) + by\n",
    "predictions = tf.argmax(logits, axis=2)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_y_oh)\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(10001):\n",
    "        randomStringGenerator = random_string_generator(batch_size=batch_size, chars=sequence_length)\n",
    "        x, y = next(randomStringGenerator)\n",
    "#         print('run {0} --------'.format(epoch))\n",
    "\n",
    "        feed_dict = {tf_x: x, tf_y: y}\n",
    "        o, l, opt = sess.run([predictions, loss, optimizer], feed_dict=feed_dict)\n",
    "#         o, l, opt, s = sess.run([predictions, loss, optimizer, outputs_train], feed_dict=feed_dict)\n",
    "\n",
    "#         print(s.shape)\n",
    "        if(epoch % 1000 == 0):\n",
    "            print('run {0} --------'.format(epoch))\n",
    "#             print('input:', x)\n",
    "            print('target:', y)\n",
    "            print('output:', o)\n",
    "            print('loss:', l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)\n",
    "print(dir(mnist.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TrainGenerator(batch_size=128):\n",
    "    while True:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size*3)\n",
    "        batch_x = batch_x.reshape(-1, 28, 28)\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(batch_size):\n",
    "            img = np.concatenate((batch_x[i], batch_x[i+batch_size], batch_x[i+batch_size*2]), axis=1) #combine 3 images horizontally\n",
    "            label = [batch_y[i], batch_y[i+batch_size], batch_y[i+batch_size*2]]\n",
    "            x.append(img)\n",
    "            y.append(label)\n",
    "        \n",
    "        yield np.stack(x), np.stack(y)\n",
    "\n",
    "gen = TrainGenerator()\n",
    "x, y = next(gen)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "plt.imshow(x[0], cmap='gray')\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
