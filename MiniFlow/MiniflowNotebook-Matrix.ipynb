{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the linear version with matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    Base class for layers in the network.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `inbound_layers`: A list of layers with edges into this layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, inbound_layers=[]):\n",
    "        \"\"\"\n",
    "        Layer's constructor (runs when the object is instantiated). Sets\n",
    "        properties that all layers need.\n",
    "        \"\"\"\n",
    "        # A list of layers with edges into this layer.\n",
    "        self.inbound_layers = inbound_layers\n",
    "        # The eventual value of this layer. Set by running\n",
    "        # the forward() method.\n",
    "        self.value = None\n",
    "        # A list of layers that this layer outputs to.\n",
    "        self.outbound_layers = []\n",
    "        # Sets this layer as an outbound layer for all of\n",
    "        # this layer's inputs.\n",
    "        for layer in inbound_layers:\n",
    "            layer.outbound_layers.append(self)\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Every layer that uses this class as a base class will\n",
    "        need to define its own `forward` method.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Layer):\n",
    "    \"\"\"\n",
    "    A generic input into the network.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # The base class constructor has to run to set all\n",
    "        # the properties here.\n",
    "        #\n",
    "        # The most important property on an Input is value.\n",
    "        # self.value is set during `topological_sort` later.\n",
    "        Layer.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    \"\"\"\n",
    "    Represents a layer that performs a linear transform.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, W, b):\n",
    "        # The base class (Layer) constructor. Weights and bias\n",
    "        # are treated like inbound layers.\n",
    "        Layer.__init__(self, [X, W, b])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Performs the math behind a linear transform.\n",
    "        \"\"\"\n",
    "        X = self.inbound_layers[0].value\n",
    "        W = self.inbound_layers[1].value\n",
    "        b = self.inbound_layers[2].value\n",
    "        self.value = np.dot(X, W) + b\n",
    "\n",
    "\n",
    "class Sigmoid(Layer):\n",
    "    \"\"\"\n",
    "    Represents a layer that performs the sigmoid activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer):\n",
    "        # The base class constructor.\n",
    "        Layer.__init__(self, [layer])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        This method is separate from `forward` because it\n",
    "        will be used with `backward` as well.\n",
    "\n",
    "        `x`: A numpy array-like object.\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Perform the sigmoid function and set the value.\n",
    "        \"\"\"\n",
    "        input_value = self.inbound_layers[0].value\n",
    "        self.value = self._sigmoid(input_value)\n",
    "\n",
    "\n",
    "class MSE(Layer):\n",
    "    def __init__(self, y, a):\n",
    "        \"\"\"\n",
    "        The mean squared error cost function.\n",
    "        Should be used as the last layer for a network.\n",
    "        \"\"\"\n",
    "        # Call the base class' constructor.\n",
    "        Layer.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Calculates the mean squared error.\n",
    "        \"\"\"\n",
    "        # NOTE: We reshape these to avoid possible matrix/vector broadcast\n",
    "        # errors.\n",
    "        #\n",
    "        # For example, if we subtract an array of shape (3,) from an array of shape\n",
    "        # (3,1) we get an array of shape(3,3) as the result when we want\n",
    "        # an array of shape (3,1) instead.\n",
    "        #\n",
    "        # Making both arrays (3,1) insures the result is (3,1) and does\n",
    "        # an elementwise subtraction as expected.\n",
    "        y = self.inbound_layers[0].value.reshape(-1, 1)\n",
    "        a = self.inbound_layers[1].value.reshape(-1, 1)\n",
    "        # TODO: your code here\n",
    "#         print(y)\n",
    "#         print(a)\n",
    "        self.value = np.power((y - a), 2).mean()\n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the layers in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Layer and the value is the respective value feed to that Layer.\n",
    "\n",
    "    Returns a list of sorted layers.\n",
    "    \"\"\"\n",
    "\n",
    "    input_layers = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    layers = [n for n in input_layers]\n",
    "    while len(layers) > 0:\n",
    "        n = layers.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_layers:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            layers.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_layers)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_layers:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(graph):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted Layers.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `graph`: The result of calling `topological_sort`.\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    for n in graph:\n",
    "        n.forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.4166666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test your MSE method with this script!\n",
    "\n",
    "No changes necessary, but feel free to play\n",
    "with this script to test your network.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "# from miniflow import *\n",
    "\n",
    "y, a = Input(), Input()\n",
    "cost = MSE(y, a) \n",
    "\n",
    "y_ = np.array([1, 2, 3])\n",
    "a_ = np.array([4.5, 5, 10])\n",
    "\n",
    "feed_dict = {y: y_, a: a_}\n",
    "graph = topological_sort(feed_dict)\n",
    "# forward pass\n",
    "forward_pass(graph)\n",
    "\n",
    "\"\"\"\n",
    "Expected output\n",
    "\n",
    "23.4166666667\n",
    "\"\"\"\n",
    "print(cost.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_update(x, gradx, learning_rate):\n",
    "    \"\"\"\n",
    "    Performs a gradient descent update.\n",
    "    \"\"\"\n",
    "    # TODO: Implement gradient descent.\n",
    "    \n",
    "    # Return the new value for x\n",
    "    return x - learning_rate * gradx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: Cost = 21.000, x = 8.000\n",
      "EPOCH 1: Cost = 15.240, x = 6.400\n",
      "EPOCH 2: Cost = 11.554, x = 5.120\n",
      "EPOCH 3: Cost = 9.194, x = 4.096\n",
      "EPOCH 4: Cost = 7.684, x = 3.277\n",
      "EPOCH 5: Cost = 6.718, x = 2.621\n",
      "EPOCH 6: Cost = 6.100, x = 2.097\n",
      "EPOCH 7: Cost = 5.704, x = 1.678\n",
      "EPOCH 8: Cost = 5.450, x = 1.342\n",
      "EPOCH 9: Cost = 5.288, x = 1.074\n",
      "EPOCH 10: Cost = 5.184, x = 0.859\n",
      "EPOCH 11: Cost = 5.118, x = 0.687\n",
      "EPOCH 12: Cost = 5.076, x = 0.550\n",
      "EPOCH 13: Cost = 5.048, x = 0.440\n",
      "EPOCH 14: Cost = 5.031, x = 0.352\n",
      "EPOCH 15: Cost = 5.020, x = 0.281\n",
      "EPOCH 16: Cost = 5.013, x = 0.225\n",
      "EPOCH 17: Cost = 5.008, x = 0.180\n",
      "EPOCH 18: Cost = 5.005, x = 0.144\n",
      "EPOCH 19: Cost = 5.003, x = 0.115\n",
      "EPOCH 20: Cost = 5.002, x = 0.092\n",
      "EPOCH 21: Cost = 5.001, x = 0.074\n",
      "EPOCH 22: Cost = 5.001, x = 0.059\n",
      "EPOCH 23: Cost = 5.001, x = 0.047\n",
      "EPOCH 24: Cost = 5.000, x = 0.038\n",
      "EPOCH 25: Cost = 5.000, x = 0.030\n",
      "EPOCH 26: Cost = 5.000, x = 0.024\n",
      "EPOCH 27: Cost = 5.000, x = 0.019\n",
      "EPOCH 28: Cost = 5.000, x = 0.015\n",
      "EPOCH 29: Cost = 5.000, x = 0.012\n",
      "EPOCH 30: Cost = 5.000, x = 0.010\n",
      "EPOCH 31: Cost = 5.000, x = 0.008\n",
      "EPOCH 32: Cost = 5.000, x = 0.006\n",
      "EPOCH 33: Cost = 5.000, x = 0.005\n",
      "EPOCH 34: Cost = 5.000, x = 0.004\n",
      "EPOCH 35: Cost = 5.000, x = 0.003\n",
      "EPOCH 36: Cost = 5.000, x = 0.003\n",
      "EPOCH 37: Cost = 5.000, x = 0.002\n",
      "EPOCH 38: Cost = 5.000, x = 0.002\n",
      "EPOCH 39: Cost = 5.000, x = 0.001\n",
      "EPOCH 40: Cost = 5.000, x = 0.001\n",
      "EPOCH 41: Cost = 5.000, x = 0.001\n",
      "EPOCH 42: Cost = 5.000, x = 0.001\n",
      "EPOCH 43: Cost = 5.000, x = 0.001\n",
      "EPOCH 44: Cost = 5.000, x = 0.000\n",
      "EPOCH 45: Cost = 5.000, x = 0.000\n",
      "EPOCH 46: Cost = 5.000, x = 0.000\n",
      "EPOCH 47: Cost = 5.000, x = 0.000\n",
      "EPOCH 48: Cost = 5.000, x = 0.000\n",
      "EPOCH 49: Cost = 5.000, x = 0.000\n",
      "EPOCH 50: Cost = 5.000, x = 0.000\n",
      "EPOCH 51: Cost = 5.000, x = 0.000\n",
      "EPOCH 52: Cost = 5.000, x = 0.000\n",
      "EPOCH 53: Cost = 5.000, x = 0.000\n",
      "EPOCH 54: Cost = 5.000, x = 0.000\n",
      "EPOCH 55: Cost = 5.000, x = 0.000\n",
      "EPOCH 56: Cost = 5.000, x = 0.000\n",
      "EPOCH 57: Cost = 5.000, x = 0.000\n",
      "EPOCH 58: Cost = 5.000, x = 0.000\n",
      "EPOCH 59: Cost = 5.000, x = 0.000\n",
      "EPOCH 60: Cost = 5.000, x = 0.000\n",
      "EPOCH 61: Cost = 5.000, x = 0.000\n",
      "EPOCH 62: Cost = 5.000, x = 0.000\n",
      "EPOCH 63: Cost = 5.000, x = 0.000\n",
      "EPOCH 64: Cost = 5.000, x = 0.000\n",
      "EPOCH 65: Cost = 5.000, x = 0.000\n",
      "EPOCH 66: Cost = 5.000, x = 0.000\n",
      "EPOCH 67: Cost = 5.000, x = 0.000\n",
      "EPOCH 68: Cost = 5.000, x = 0.000\n",
      "EPOCH 69: Cost = 5.000, x = 0.000\n",
      "EPOCH 70: Cost = 5.000, x = 0.000\n",
      "EPOCH 71: Cost = 5.000, x = 0.000\n",
      "EPOCH 72: Cost = 5.000, x = 0.000\n",
      "EPOCH 73: Cost = 5.000, x = 0.000\n",
      "EPOCH 74: Cost = 5.000, x = 0.000\n",
      "EPOCH 75: Cost = 5.000, x = 0.000\n",
      "EPOCH 76: Cost = 5.000, x = 0.000\n",
      "EPOCH 77: Cost = 5.000, x = 0.000\n",
      "EPOCH 78: Cost = 5.000, x = 0.000\n",
      "EPOCH 79: Cost = 5.000, x = 0.000\n",
      "EPOCH 80: Cost = 5.000, x = 0.000\n",
      "EPOCH 81: Cost = 5.000, x = 0.000\n",
      "EPOCH 82: Cost = 5.000, x = 0.000\n",
      "EPOCH 83: Cost = 5.000, x = 0.000\n",
      "EPOCH 84: Cost = 5.000, x = 0.000\n",
      "EPOCH 85: Cost = 5.000, x = 0.000\n",
      "EPOCH 86: Cost = 5.000, x = 0.000\n",
      "EPOCH 87: Cost = 5.000, x = 0.000\n",
      "EPOCH 88: Cost = 5.000, x = 0.000\n",
      "EPOCH 89: Cost = 5.000, x = 0.000\n",
      "EPOCH 90: Cost = 5.000, x = 0.000\n",
      "EPOCH 91: Cost = 5.000, x = 0.000\n",
      "EPOCH 92: Cost = 5.000, x = 0.000\n",
      "EPOCH 93: Cost = 5.000, x = 0.000\n",
      "EPOCH 94: Cost = 5.000, x = 0.000\n",
      "EPOCH 95: Cost = 5.000, x = 0.000\n",
      "EPOCH 96: Cost = 5.000, x = 0.000\n",
      "EPOCH 97: Cost = 5.000, x = 0.000\n",
      "EPOCH 98: Cost = 5.000, x = 0.000\n",
      "EPOCH 99: Cost = 5.000, x = 0.000\n",
      "EPOCH 100: Cost = 5.000, x = 0.000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given the starting point of any `x` gradient descent\n",
    "should be able to find the minimum value of x for the\n",
    "cost function `f` defined below.\n",
    "\"\"\"\n",
    "import random\n",
    "# from gd import gradient_descent_update\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Quadratic function.\n",
    "\n",
    "    It's easy to see the minimum value of the function\n",
    "    is 5 when is x=0.\n",
    "    \"\"\"\n",
    "    return x**2 + 5\n",
    "\n",
    "\n",
    "def df(x):\n",
    "    \"\"\"\n",
    "    Derivative of `f` with respect to `x`.\n",
    "    \"\"\"\n",
    "    return 2*x\n",
    "\n",
    "\n",
    "# Random number better 0 and 10,000. Feel free to set x whatever you like.\n",
    "x = random.randint(0, 10)\n",
    "# TODO: Set the learning rate\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "for i in range(epochs+1):\n",
    "    cost = f(x)\n",
    "    gradx = df(x)\n",
    "    print(\"EPOCH {}: Cost = {:.3f}, x = {:.3f}\".format(i, cost, gradx))\n",
    "    x = gradient_descent_update(x, gradx, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
